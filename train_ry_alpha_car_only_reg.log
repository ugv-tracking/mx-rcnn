Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 347, in get_vgg_train
    rpn_bbox_loss = mx.sym.MakeLoss(name='rpn_bbox_loss', data=rpn_bbox_loss__, grad_scale=1.0 / config.TRAIN.RPN_BATCH_SIZE)
NameError: global name 'rpn_bbox_loss__' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 43, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "<string>", line 1, in <module>
NameError: name 'Kitti' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 43, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/train_ry_alpha_car_only.lst
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
[07:58:24] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.23 samples/sec	Train-RPNAcc=0.684896,	RPNLogLoss=0.671247,	RPNL1Loss=0.494725,	RCNNAcc=0.168527,	RCNNLogLoss=2.884160,	RCNNL1Loss=0.328817,	
INFO:root:Epoch[1] Batch [40]	Speed: 2.28 samples/sec	Train-RPNAcc=0.700362,	RPNLogLoss=0.667373,	RPNL1Loss=0.458141,	RCNNAcc=0.473323,	RCNNLogLoss=2.441511,	RCNNL1Loss=0.347707,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
[08:02:42] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [08:02:42] src/ndarray/ndarray.cc:665: Check failed: fi->Read(&header) Invalid NDArray file format

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fea2b46e71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet7NDArray4LoadEPN4dmlc6StreamEPSt6vectorIS0_SaIS0_EEPS4_ISsSaISsEE+0xa5) [0x7fea2bd38ec5]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x215) [0x7fea2bc4f225]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fead499dadc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fead499d40c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fead4bb45fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fead4bb5f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fead5f2bf45]
[bt] (20) python() [0x578c4e]

Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 59, in train_net
    arg_params, aux_params = load_param(pretrained, epoch, convert=True)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/utils/load_model.py", line 49, in load_param
    arg_params, aux_params = load_checkpoint(prefix, epoch)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/utils/load_model.py", line 15, in load_checkpoint
    save_dict = mx.nd.load('%s-%04d.params' % (prefix, epoch))
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 1247, in load
    ctypes.byref(names)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [08:02:42] src/ndarray/ndarray.cc:665: Check failed: fi->Read(&header) Invalid NDArray file format

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fea2b46e71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet7NDArray4LoadEPN4dmlc6StreamEPSt6vectorIS0_SaIS0_EEPS4_ISsSaISsEE+0xa5) [0x7fea2bd38ec5]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x215) [0x7fea2bc4f225]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fead499dadc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fead499d40c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fead4bb45fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fead4bb5f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fead5f2bf45]
[bt] (20) python() [0x578c4e]

train_end2end.sh: 5: train_end2end.sh: --prefix: not found
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
[08:07:10] include/dmlc/logging.h:300: [08:07:10] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0001.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7fa38425d969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7fa384255d6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7fa383ee8213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fa42cc36adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fa42cc3640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fa42ce4d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fa42ce4ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fa42e1c4f45]
[bt] (20) python() [0x578c4e]

Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 59, in train_net
    arg_params, aux_params = load_param(pretrained, epoch, convert=True)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/utils/load_model.py", line 49, in load_param
    arg_params, aux_params = load_checkpoint(prefix, epoch)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/utils/load_model.py", line 15, in load_checkpoint
    save_dict = mx.nd.load('%s-%04d.params' % (prefix, epoch))
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 1247, in load
    ctypes.byref(names)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [08:07:10] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0001.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7fa38425d969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7fa384255d6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7fa383ee8213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fa42cc36adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fa42cc3640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fa42ce4d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fa42ce4ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fa42e1c4f45]
[bt] (20) python() [0x578c4e]

{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
[08:07:50] include/dmlc/logging.h:300: [08:07:50] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0001.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7f2fab1f7969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7f2fab1efd6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7f2faae82213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f3053bd0adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f3053bd040c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f3053de75fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f3053de8f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f305515ef45]
[bt] (20) python() [0x578c4e]

Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 59, in train_net
    arg_params, aux_params = load_param(pretrained, epoch, convert=True)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/utils/load_model.py", line 49, in load_param
    arg_params, aux_params = load_checkpoint(prefix, epoch)
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/utils/load_model.py", line 15, in load_checkpoint
    save_dict = mx.nd.load('%s-%04d.params' % (prefix, epoch))
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 1247, in load
    ctypes.byref(names)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [08:07:50] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0001.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7f2fab1f7969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7f2fab1efd6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7f2faae82213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f3053bd0adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f3053bd040c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f3053de75fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f3053de8f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f305515ef45]
[bt] (20) python() [0x578c4e]

{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
[08:08:30] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.39 samples/sec	Train-RPNAcc=0.695499,	RPNLogLoss=0.670038,	RPNL1Loss=0.508623,	RCNNAcc=0.164807,	RCNNLogLoss=2.885022,	RCNNL1Loss=0.461403,	
INFO:root:Epoch[1] Batch [40]	Speed: 1.86 samples/sec	Train-RPNAcc=0.699219,	RPNLogLoss=0.668081,	RPNL1Loss=0.528435,	RCNNAcc=0.455793,	RCNNLogLoss=2.461794,	RCNNL1Loss=0.435806,	
INFO:root:Epoch[1] Batch [60]	Speed: 2.29 samples/sec	Train-RPNAcc=0.718366,	RPNLogLoss=0.664963,	RPNL1Loss=0.481326,	RCNNAcc=0.587346,	RCNNLogLoss=2.053479,	RCNNL1Loss=0.399580,	
INFO:root:Epoch[1] Batch [80]	Speed: 2.21 samples/sec	Train-RPNAcc=0.724537,	RPNLogLoss=0.662042,	RPNL1Loss=0.501861,	RCNNAcc=0.647666,	RCNNLogLoss=1.776625,	RCNNL1Loss=0.406845,	
INFO:root:Epoch[1] Batch [100]	Speed: 2.26 samples/sec	Train-RPNAcc=0.732635,	RPNLogLoss=0.658382,	RPNL1Loss=0.498918,	RCNNAcc=0.687268,	RCNNLogLoss=1.567237,	RCNNL1Loss=0.398295,	
INFO:root:Epoch[1] Batch [120]	Speed: 1.93 samples/sec	Train-RPNAcc=0.739443,	RPNLogLoss=0.654609,	RPNL1Loss=0.500548,	RCNNAcc=0.715134,	RCNNLogLoss=1.416785,	RCNNL1Loss=0.394066,	
INFO:root:Epoch[1] Batch [140]	Speed: 2.31 samples/sec	Train-RPNAcc=0.748449,	RPNLogLoss=0.649856,	RPNL1Loss=0.480898,	RCNNAcc=0.734043,	RCNNLogLoss=1.304172,	RCNNL1Loss=0.392019,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 89, in train_net
    'shape inconsistent for ' + k + ' inferred ' + str(arg_shape_dict[k]) + ' provided ' + str(arg_params[k].shape)
AssertionError: shape inconsistent for fc7_weight inferred (1024L, 4096L) provided (4096L, 4096L)
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
[08:31:34] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
[08:42:10] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 89, in train_net
    'shape inconsistent for ' + k + ' inferred ' + str(arg_shape_dict[k]) + ' provided ' + str(arg_params[k].shape)
AssertionError: shape inconsistent for fc7_weight inferred (1024L, 4096L) provided (4096L, 4096L)
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
Traceback (most recent call last):
  File "train_end2end.py", line 178, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 89, in train_net
    'shape inconsistent for ' + k + ' inferred ' + str(arg_shape_dict[k]) + ' provided ' + str(arg_params[k].shape)
AssertionError: shape inconsistent for fc6_weight inferred (1024L, 25088L) provided (4096L, 25088L)
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 1024L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 1024L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (1024L,),
 'fc6_weight': (1024L, 25088L),
 'fc7_bias': (1024L,),
 'fc7_weight': (1024L, 1024L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 182, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 93, in train_net
    'shape inconsistent for ' + k + ' inferred ' + str(arg_shape_dict[k]) + ' provided ' + str(arg_params[k].shape)
AssertionError: shape inconsistent for fc6_weight inferred (1024L, 25088L) provided (4096L, 25088L)
  File "train_end2end.py", line 77
    arg_params['fc6_bias'] = mx.random.zeros(shape=arg_shape_dict['fc6_bias'])
    ^
IndentationError: unexpected indent
  File "train_end2end.py", line 77
    arg_params['fc6_bias'] = mx.random.zeros(shape=arg_shape_dict['fc6_bias'])
    ^
IndentationError: unexpected indent
  File "train_end2end.py", line 77
    arg_params['fc6_bias'] = mx.random.zeros(shape=arg_shape_dict['fc6_bias'])
    ^
IndentationError: unexpected indent
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 1024L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 1024L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (1024L,),
 'fc6_weight': (1024L, 25088L),
 'fc7_bias': (1024L,),
 'fc7_weight': (1024L, 1024L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 77, in train_net
    arg_params['fc6_bias'] = mx.random.zeros(shape=arg_shape_dict['fc6_bias'])
AttributeError: 'module' object has no attribute 'zeros'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 1024L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 1024L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (1024L,),
 'fc6_weight': (1024L, 25088L),
 'fc7_bias': (1024L,),
 'fc7_weight': (1024L, 1024L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 78, in train_net
    arg_params['fc7_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc67_weight'])
KeyError: 'fc67_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 1024L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 1024L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (1024L,),
 'fc6_weight': (1024L, 25088L),
 'fc7_bias': (1024L,),
 'fc7_weight': (1024L, 1024L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[08:56:16] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.29 samples/sec	Train-RPNAcc=0.421131,	RPNLogLoss=0.706408,	RPNL1Loss=0.515277,	RCNNAcc=0.084449,	RCNNLogLoss=3.000782,	RCNNL1Loss=0.330699,	
INFO:root:Epoch[1] Batch [40]	Speed: 2.10 samples/sec	Train-RPNAcc=0.461604,	RPNLogLoss=0.700490,	RPNL1Loss=0.543918,	RCNNAcc=0.186738,	RCNNLogLoss=2.947460,	RCNNL1Loss=0.357679,	
INFO:root:Epoch[1] Batch [60]	Speed: 2.48 samples/sec	Train-RPNAcc=0.497695,	RPNLogLoss=0.697222,	RPNL1Loss=0.510145,	RCNNAcc=0.321209,	RCNNLogLoss=2.885031,	RCNNL1Loss=0.341472,	
INFO:root:Epoch[1] Batch [80]	Speed: 2.43 samples/sec	Train-RPNAcc=0.525367,	RPNLogLoss=0.694149,	RPNL1Loss=0.505115,	RCNNAcc=0.427373,	RCNNLogLoss=2.826519,	RCNNL1Loss=0.358289,	
INFO:root:Epoch[1] Batch [100]	Speed: 2.47 samples/sec	Train-RPNAcc=0.554146,	RPNLogLoss=0.689585,	RPNL1Loss=0.511747,	RCNNAcc=0.511448,	RCNNLogLoss=2.752067,	RCNNL1Loss=0.355651,	
INFO:root:Epoch[1] Batch [120]	Speed: 2.10 samples/sec	Train-RPNAcc=0.587842,	RPNLogLoss=0.684018,	RPNL1Loss=0.486696,	RCNNAcc=0.571604,	RCNNLogLoss=2.669766,	RCNNL1Loss=0.346446,	
INFO:root:Epoch[1] Batch [140]	Speed: 2.47 samples/sec	Train-RPNAcc=0.612589,	RPNLogLoss=0.678712,	RPNL1Loss=0.475513,	RCNNAcc=0.612921,	RCNNLogLoss=2.578432,	RCNNL1Loss=0.349929,	
INFO:root:Epoch[1] Batch [160]	Speed: 2.37 samples/sec	Train-RPNAcc=0.627742,	RPNLogLoss=0.672882,	RPNL1Loss=0.478982,	RCNNAcc=0.642178,	RCNNLogLoss=2.469300,	RCNNL1Loss=0.353064,	
INFO:root:Epoch[1] Batch [180]	Speed: 2.24 samples/sec	Train-RPNAcc=0.640301,	RPNLogLoss=0.663300,	RPNL1Loss=0.483681,	RCNNAcc=0.665185,	RCNNLogLoss=2.328230,	RCNNL1Loss=0.354017,	
INFO:root:Epoch[1] Batch [200]	Speed: 1.91 samples/sec	Train-RPNAcc=0.652732,	RPNLogLoss=0.650679,	RPNL1Loss=0.472685,	RCNNAcc=0.686101,	RCNNLogLoss=2.177297,	RCNNL1Loss=0.345670,	
INFO:root:Epoch[1] Batch [220]	Speed: 2.07 samples/sec	Train-RPNAcc=0.668092,	RPNLogLoss=0.632362,	RPNL1Loss=0.453068,	RCNNAcc=0.705211,	RCNNLogLoss=2.032665,	RCNNL1Loss=0.335954,	
INFO:root:Epoch[1] Batch [240]	Speed: 1.87 samples/sec	Train-RPNAcc=0.676268,	RPNLogLoss=0.615736,	RPNL1Loss=0.441088,	RCNNAcc=0.714601,	RCNNLogLoss=1.939973,	RCNNL1Loss=0.346047,	
INFO:root:Epoch[1] Batch [260]	Speed: 1.63 samples/sec	Train-RPNAcc=0.688832,	RPNLogLoss=0.598860,	RPNL1Loss=0.421230,	RCNNAcc=0.725156,	RCNNLogLoss=1.849326,	RCNNL1Loss=0.346090,	
INFO:root:Epoch[1] Batch [280]	Speed: 1.88 samples/sec	Train-RPNAcc=0.698246,	RPNLogLoss=0.583833,	RPNL1Loss=0.407530,	RCNNAcc=0.733068,	RCNNLogLoss=1.772152,	RCNNL1Loss=0.349152,	
INFO:root:Epoch[1] Batch [300]	Speed: 1.87 samples/sec	Train-RPNAcc=0.704007,	RPNLogLoss=0.570521,	RPNL1Loss=0.396372,	RCNNAcc=0.740137,	RCNNLogLoss=1.699218,	RCNNL1Loss=0.352761,	
INFO:root:Epoch[1] Batch [320]	Speed: 1.86 samples/sec	Train-RPNAcc=0.711996,	RPNLogLoss=0.556205,	RPNL1Loss=0.382743,	RCNNAcc=0.746447,	RCNNLogLoss=1.633587,	RCNNL1Loss=0.355425,	
INFO:root:Epoch[1] Batch [340]	Speed: 1.79 samples/sec	Train-RPNAcc=0.718635,	RPNLogLoss=0.543426,	RPNL1Loss=0.372411,	RCNNAcc=0.749656,	RCNNLogLoss=1.578394,	RCNNL1Loss=0.362513,	
INFO:root:Epoch[1] Batch [360]	Speed: 1.89 samples/sec	Train-RPNAcc=0.725589,	RPNLogLoss=0.530821,	RPNL1Loss=0.361442,	RCNNAcc=0.755324,	RCNNLogLoss=1.519612,	RCNNL1Loss=0.361754,	
INFO:root:Epoch[1] Batch [380]	Speed: 1.82 samples/sec	Train-RPNAcc=0.730828,	RPNLogLoss=0.519980,	RPNL1Loss=0.353499,	RCNNAcc=0.760294,	RCNNLogLoss=1.465657,	RCNNL1Loss=0.362095,	
INFO:root:Epoch[1] Batch [400]	Speed: 1.66 samples/sec	Train-RPNAcc=0.735515,	RPNLogLoss=0.510217,	RPNL1Loss=0.346557,	RCNNAcc=0.764612,	RCNNLogLoss=1.417376,	RCNNL1Loss=0.361931,	
INFO:root:Epoch[1] Batch [420]	Speed: 1.72 samples/sec	Train-RPNAcc=0.740907,	RPNLogLoss=0.501202,	RPNL1Loss=0.341024,	RCNNAcc=0.770190,	RCNNLogLoss=1.369539,	RCNNL1Loss=0.358619,	
INFO:root:Epoch[1] Batch [440]	Speed: 1.70 samples/sec	Train-RPNAcc=0.746085,	RPNLogLoss=0.493036,	RPNL1Loss=0.332940,	RCNNAcc=0.772516,	RCNNLogLoss=1.330998,	RCNNL1Loss=0.361965,	
INFO:root:Epoch[1] Batch [460]	Speed: 1.69 samples/sec	Train-RPNAcc=0.750500,	RPNLogLoss=0.485699,	RPNL1Loss=0.326692,	RCNNAcc=0.776064,	RCNNLogLoss=1.291163,	RCNNL1Loss=0.360987,	
INFO:root:Epoch[1] Batch [480]	Speed: 1.67 samples/sec	Train-RPNAcc=0.754921,	RPNLogLoss=0.478206,	RPNL1Loss=0.320706,	RCNNAcc=0.778895,	RCNNLogLoss=1.255895,	RCNNL1Loss=0.363306,	
INFO:root:Epoch[1] Batch [500]	Speed: 1.45 samples/sec	Train-RPNAcc=0.758163,	RPNLogLoss=0.471903,	RPNL1Loss=0.315312,	RCNNAcc=0.781655,	RCNNLogLoss=1.223132,	RCNNL1Loss=0.364143,	
INFO:root:Epoch[1] Batch [520]	Speed: 1.66 samples/sec	Train-RPNAcc=0.761591,	RPNLogLoss=0.466072,	RPNL1Loss=0.310859,	RCNNAcc=0.783544,	RCNNLogLoss=1.193766,	RCNNL1Loss=0.366914,	
INFO:root:Epoch[1] Batch [540]	Speed: 1.66 samples/sec	Train-RPNAcc=0.764816,	RPNLogLoss=0.459487,	RPNL1Loss=0.305733,	RCNNAcc=0.784976,	RCNNLogLoss=1.166504,	RCNNL1Loss=0.370728,	
INFO:root:Epoch[1] Batch [560]	Speed: 1.66 samples/sec	Train-RPNAcc=0.767589,	RPNLogLoss=0.454272,	RPNL1Loss=0.300650,	RCNNAcc=0.787252,	RCNNLogLoss=1.139233,	RCNNL1Loss=0.370778,	
INFO:root:Epoch[1] Batch [580]	Speed: 1.64 samples/sec	Train-RPNAcc=0.770224,	RPNLogLoss=0.449083,	RPNL1Loss=0.296285,	RCNNAcc=0.788242,	RCNNLogLoss=1.115663,	RCNNL1Loss=0.374820,	
INFO:root:Epoch[1] Batch [600]	Speed: 1.61 samples/sec	Train-RPNAcc=0.772203,	RPNLogLoss=0.445369,	RPNL1Loss=0.291952,	RCNNAcc=0.789011,	RCNNLogLoss=1.093619,	RCNNL1Loss=0.379101,	
INFO:root:Epoch[1] Batch [620]	Speed: 1.68 samples/sec	Train-RPNAcc=0.774526,	RPNLogLoss=0.440945,	RPNL1Loss=0.288408,	RCNNAcc=0.790698,	RCNNLogLoss=1.071114,	RCNNL1Loss=0.380207,	
INFO:root:Epoch[1] Batch [640]	Speed: 1.55 samples/sec	Train-RPNAcc=0.776850,	RPNLogLoss=0.436501,	RPNL1Loss=0.284330,	RCNNAcc=0.791805,	RCNNLogLoss=1.050916,	RCNNL1Loss=0.383864,	
INFO:root:Epoch[1] Batch [660]	Speed: 1.64 samples/sec	Train-RPNAcc=0.779306,	RPNLogLoss=0.432264,	RPNL1Loss=0.281344,	RCNNAcc=0.794074,	RCNNLogLoss=1.029747,	RCNNL1Loss=0.384244,	
INFO:root:Epoch[1] Batch [680]	Speed: 1.61 samples/sec	Train-RPNAcc=0.781978,	RPNLogLoss=0.427445,	RPNL1Loss=0.277496,	RCNNAcc=0.795934,	RCNNLogLoss=1.010196,	RCNNL1Loss=0.384577,	
INFO:root:Epoch[1] Batch [700]	Speed: 1.69 samples/sec	Train-RPNAcc=0.784593,	RPNLogLoss=0.422978,	RPNL1Loss=0.273443,	RCNNAcc=0.798335,	RCNNLogLoss=0.990134,	RCNNL1Loss=0.382667,	
INFO:root:Epoch[1] Batch [720]	Speed: 1.66 samples/sec	Train-RPNAcc=0.787464,	RPNLogLoss=0.418148,	RPNL1Loss=0.269190,	RCNNAcc=0.800559,	RCNNLogLoss=0.971299,	RCNNL1Loss=0.382528,	
INFO:root:Epoch[1] Batch [740]	Speed: 1.61 samples/sec	Train-RPNAcc=0.789068,	RPNLogLoss=0.415216,	RPNL1Loss=0.266642,	RCNNAcc=0.801746,	RCNNLogLoss=0.955600,	RCNNL1Loss=0.384430,	
INFO:root:Epoch[1] Batch [760]	Speed: 1.32 samples/sec	Train-RPNAcc=0.791198,	RPNLogLoss=0.411586,	RPNL1Loss=0.263529,	RCNNAcc=0.803456,	RCNNLogLoss=0.939635,	RCNNL1Loss=0.385307,	
INFO:root:Epoch[1] Batch [780]	Speed: 1.46 samples/sec	Train-RPNAcc=0.792429,	RPNLogLoss=0.409879,	RPNL1Loss=0.262584,	RCNNAcc=0.804407,	RCNNLogLoss=0.925259,	RCNNL1Loss=0.386659,	
INFO:root:Epoch[1] Batch [800]	Speed: 1.53 samples/sec	Train-RPNAcc=0.793954,	RPNLogLoss=0.406880,	RPNL1Loss=0.260399,	RCNNAcc=0.805897,	RCNNLogLoss=0.910872,	RCNNL1Loss=0.388107,	
INFO:root:Epoch[1] Batch [820]	Speed: 1.52 samples/sec	Train-RPNAcc=0.795752,	RPNLogLoss=0.404188,	RPNL1Loss=0.257976,	RCNNAcc=0.806933,	RCNNLogLoss=0.897438,	RCNNL1Loss=0.390036,	
INFO:root:Epoch[1] Batch [840]	Speed: 1.55 samples/sec	Train-RPNAcc=0.797432,	RPNLogLoss=0.401528,	RPNL1Loss=0.255955,	RCNNAcc=0.808431,	RCNNLogLoss=0.883881,	RCNNL1Loss=0.391750,	
INFO:root:Epoch[1] Batch [860]	Speed: 1.51 samples/sec	Train-RPNAcc=0.799003,	RPNLogLoss=0.398516,	RPNL1Loss=0.253505,	RCNNAcc=0.809814,	RCNNLogLoss=0.871135,	RCNNL1Loss=0.392888,	
INFO:root:Epoch[1] Batch [880]	Speed: 1.66 samples/sec	Train-RPNAcc=0.800564,	RPNLogLoss=0.395379,	RPNL1Loss=0.250484,	RCNNAcc=0.811454,	RCNNLogLoss=0.858019,	RCNNL1Loss=0.392648,	
INFO:root:Epoch[1] Batch [900]	Speed: 1.56 samples/sec	Train-RPNAcc=0.801809,	RPNLogLoss=0.392851,	RPNL1Loss=0.247897,	RCNNAcc=0.812968,	RCNNLogLoss=0.845497,	RCNNL1Loss=0.392982,	
INFO:root:Epoch[1] Batch [920]	Speed: 1.57 samples/sec	Train-RPNAcc=0.803835,	RPNLogLoss=0.390055,	RPNL1Loss=0.245891,	RCNNAcc=0.814476,	RCNNLogLoss=0.833416,	RCNNL1Loss=0.392652,	
INFO:root:Epoch[1] Batch [940]	Speed: 1.54 samples/sec	Train-RPNAcc=0.805119,	RPNLogLoss=0.387647,	RPNL1Loss=0.244152,	RCNNAcc=0.815447,	RCNNLogLoss=0.823005,	RCNNL1Loss=0.394498,	
INFO:root:Epoch[1] Batch [960]	Speed: 1.41 samples/sec	Train-RPNAcc=0.806606,	RPNLogLoss=0.385241,	RPNL1Loss=0.242281,	RCNNAcc=0.816825,	RCNNLogLoss=0.812095,	RCNNL1Loss=0.395738,	
INFO:root:Epoch[1] Batch [980]	Speed: 1.56 samples/sec	Train-RPNAcc=0.808235,	RPNLogLoss=0.382858,	RPNL1Loss=0.240158,	RCNNAcc=0.818035,	RCNNLogLoss=0.801770,	RCNNL1Loss=0.397327,	
INFO:root:Epoch[1] Batch [1000]	Speed: 1.60 samples/sec	Train-RPNAcc=0.809956,	RPNLogLoss=0.379755,	RPNL1Loss=0.237939,	RCNNAcc=0.819829,	RCNNLogLoss=0.790610,	RCNNL1Loss=0.396625,	
INFO:root:Epoch[1] Batch [1020]	Speed: 1.49 samples/sec	Train-RPNAcc=0.810905,	RPNLogLoss=0.378096,	RPNL1Loss=0.236704,	RCNNAcc=0.820580,	RCNNLogLoss=0.781650,	RCNNL1Loss=0.399240,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [1040]	Speed: 1.61 samples/sec	Train-RPNAcc=0.812492,	RPNLogLoss=0.375609,	RPNL1Loss=0.235092,	RCNNAcc=0.821979,	RCNNLogLoss=0.771872,	RCNNL1Loss=0.400461,	
INFO:root:Epoch[1] Batch [1060]	Speed: 1.64 samples/sec	Train-RPNAcc=0.813951,	RPNLogLoss=0.373092,	RPNL1Loss=0.233128,	RCNNAcc=0.823074,	RCNNLogLoss=0.762931,	RCNNL1Loss=0.400819,	
INFO:root:Epoch[1] Batch [1080]	Speed: 1.56 samples/sec	Train-RPNAcc=0.815434,	RPNLogLoss=0.370716,	RPNL1Loss=0.231536,	RCNNAcc=0.824338,	RCNNLogLoss=0.753908,	RCNNL1Loss=0.401638,	
INFO:root:Epoch[1] Batch [1100]	Speed: 1.59 samples/sec	Train-RPNAcc=0.816456,	RPNLogLoss=0.368650,	RPNL1Loss=0.229986,	RCNNAcc=0.825507,	RCNNLogLoss=0.745557,	RCNNL1Loss=0.401096,	
INFO:root:Epoch[1] Batch [1120]	Speed: 1.39 samples/sec	Train-RPNAcc=0.817716,	RPNLogLoss=0.366289,	RPNL1Loss=0.228247,	RCNNAcc=0.826989,	RCNNLogLoss=0.736753,	RCNNL1Loss=0.400194,	
INFO:root:Epoch[1] Batch [1140]	Speed: 1.59 samples/sec	Train-RPNAcc=0.818762,	RPNLogLoss=0.364528,	RPNL1Loss=0.227023,	RCNNAcc=0.827824,	RCNNLogLoss=0.729149,	RCNNL1Loss=0.401308,	
INFO:root:Epoch[1] Batch [1160]	Speed: 1.59 samples/sec	Train-RPNAcc=0.820023,	RPNLogLoss=0.362311,	RPNL1Loss=0.225226,	RCNNAcc=0.828825,	RCNNLogLoss=0.721226,	RCNNL1Loss=0.402334,	
INFO:root:Epoch[1] Batch [1180]	Speed: 1.59 samples/sec	Train-RPNAcc=0.821229,	RPNLogLoss=0.360448,	RPNL1Loss=0.223928,	RCNNAcc=0.829878,	RCNNLogLoss=0.713519,	RCNNL1Loss=0.402227,	
INFO:root:Epoch[1] Batch [1200]	Speed: 1.53 samples/sec	Train-RPNAcc=0.822212,	RPNLogLoss=0.358615,	RPNL1Loss=0.222574,	RCNNAcc=0.831202,	RCNNLogLoss=0.705657,	RCNNL1Loss=0.401731,	
INFO:root:Epoch[1] Batch [1220]	Speed: 1.44 samples/sec	Train-RPNAcc=0.823269,	RPNLogLoss=0.356870,	RPNL1Loss=0.221705,	RCNNAcc=0.832335,	RCNNLogLoss=0.698350,	RCNNL1Loss=0.402106,	
INFO:root:Epoch[1] Batch [1240]	Speed: 1.67 samples/sec	Train-RPNAcc=0.824628,	RPNLogLoss=0.354708,	RPNL1Loss=0.220471,	RCNNAcc=0.833262,	RCNNLogLoss=0.691611,	RCNNL1Loss=0.402637,	
INFO:root:Epoch[1] Batch [1260]	Speed: 1.41 samples/sec	Train-RPNAcc=0.825576,	RPNLogLoss=0.353137,	RPNL1Loss=0.219404,	RCNNAcc=0.834178,	RCNNLogLoss=0.685022,	RCNNL1Loss=0.403373,	
INFO:root:Epoch[1] Batch [1280]	Speed: 1.62 samples/sec	Train-RPNAcc=0.826472,	RPNLogLoss=0.351713,	RPNL1Loss=0.218373,	RCNNAcc=0.834876,	RCNNLogLoss=0.678890,	RCNNL1Loss=0.404448,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_0_bias': (4096L,),
 'fc7_0_weight': (4096L, 4096L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 95, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc7_0_weight not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_0_bias': (4096L,),
 'fc7_0_weight': (4096L, 4096L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:12:27] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.44 samples/sec	Train-RPNAcc=0.458147,	RPNLogLoss=0.701168,	RPNL1Loss=0.467548,	RCNNAcc=0.298735,	RCNNLogLoss=2.649971,	RCNNL1Loss=0.336382,	
INFO:root:Epoch[1] Batch [40]	Speed: 2.55 samples/sec	Train-RPNAcc=0.492569,	RPNLogLoss=0.695864,	RPNL1Loss=0.398860,	RCNNAcc=0.518483,	RCNNLogLoss=2.358790,	RCNNL1Loss=0.363981,	
INFO:root:Epoch[1] Batch [60]	Speed: 2.42 samples/sec	Train-RPNAcc=0.509285,	RPNLogLoss=0.692910,	RPNL1Loss=0.424407,	RCNNAcc=0.635758,	RCNNLogLoss=2.055250,	RCNNL1Loss=0.333210,	
INFO:root:Epoch[1] Batch [80]	Speed: 2.48 samples/sec	Train-RPNAcc=0.526186,	RPNLogLoss=0.689099,	RPNL1Loss=0.445988,	RCNNAcc=0.690008,	RCNNLogLoss=1.804699,	RCNNL1Loss=0.337945,	
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 379, in get_vgg_train
    fc7 = mx.symbol.FullyConnected(data=drop7_0, num_hidden=4096, name="fc7")
NameError: global name 'drop7_0' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:14:04] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.33 samples/sec	Train-RPNAcc=0.532738,	RPNLogLoss=0.695931,	RPNL1Loss=0.481951,	RCNNAcc=0.209449,	RCNNLogLoss=2.839752,	RCNNL1Loss=0.401101,	
INFO:root:Epoch[1] Batch [40]	Speed: 2.60 samples/sec	Train-RPNAcc=0.555450,	RPNLogLoss=0.692774,	RPNL1Loss=0.460450,	RCNNAcc=0.485709,	RCNNLogLoss=2.246729,	RCNNL1Loss=0.415552,	
INFO:root:Epoch[1] Batch [60]	Speed: 2.37 samples/sec	Train-RPNAcc=0.580558,	RPNLogLoss=0.689460,	RPNL1Loss=0.458158,	RCNNAcc=0.610272,	RCNNLogLoss=1.819444,	RCNNL1Loss=0.389199,	
INFO:root:Epoch[1] Batch [80]	Speed: 2.47 samples/sec	Train-RPNAcc=0.595149,	RPNLogLoss=0.686177,	RPNL1Loss=0.442905,	RCNNAcc=0.678530,	RCNNLogLoss=1.530575,	RCNNL1Loss=0.358973,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:05:04] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.07 samples/sec	Train-RPNAcc=0.554874,	RPNLogLoss=0.692884,	RPNL1Loss=0.439169,	RCNNAcc=0.204613,	RCNNLogLoss=2.822921,	RCNNL1Loss=0.306108,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 43, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/Car/mx-rcnn/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/Car/mx-rcnn/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/train_ry_alpha_car_only.lst
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 43, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/Car/mx-rcnn/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/Car/mx-rcnn/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/train_ry_alpha_car_only.lst
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
Traceback (most recent call last):
  File "train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 46, in train_net
    roidb = imdb.append_flipped_images(roidb)
  File "/home/hustxly/Car/mx-rcnn/rcnn/dataset/imdb.py", line 158, in append_flipped_images
    assert self.num_images == len(roidb)
AssertionError
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:23:01] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 1.39 samples/sec	Train-RPNAcc=0.517485,	RPNLogLoss=0.698584,	RPNL1Loss=0.539159,	RCNNAcc=0.219866,	RCNNLogLoss=2.786236,	RCNNL1Loss=0.287172,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 80, in train_net
    arg_params['fc8_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_weight'])
KeyError: 'fc8_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 1024L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_bias': (1024L,),
 'fc8_weight': (1024L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:35:09] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 1.75 samples/sec	Train-RPNAcc=0.592634,	RPNLogLoss=0.686374,	RPNL1Loss=0.489621,	RCNNAcc=0.040923,	RCNNLogLoss=3.047904,	RCNNL1Loss=0.404425,	
INFO:root:Epoch[1] Batch [40]	Speed: 1.82 samples/sec	Train-RPNAcc=0.596513,	RPNLogLoss=0.684975,	RPNL1Loss=0.493374,	RCNNAcc=0.115663,	RCNNLogLoss=2.975229,	RCNNL1Loss=0.350851,	
INFO:root:Epoch[1] Batch [60]	Speed: 1.12 samples/sec	Train-RPNAcc=0.606173,	RPNLogLoss=0.682418,	RPNL1Loss=0.488835,	RCNNAcc=0.246542,	RCNNLogLoss=2.892902,	RCNNL1Loss=0.323706,	
Traceback (most recent call last):
  File "train_end2end.py", line 9, in <module>
    from rcnn.symbol import *
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/__init__.py", line 1, in <module>
    from symbol_vgg import *
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 399
    dim_loss_ = mx.symbol.smooth_l1(name='dim_loss_', scalar=1.0, data=(dim_pred))
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 399, in get_vgg_train
    dim_loss_ = mx.symbol.smooth_l1(name='dim_loss_', scalar=1.0, data=(dim_pred))
NameError: global name 'dim_pred' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 303L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 80, in train_net
    arg_params['fc8_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_weight'])
KeyError: 'fc8_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:49:42] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_bias': (192L,),
 'fc8_weight': (192L, 4096L),
 'gt_boxes': (1L, 15L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:50:12] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 141, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (192L,),
 'dim_pred_weight': (192L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 80, in train_net
    arg_params['fc8_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_weight'])
KeyError: 'fc8_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (192L,),
 'dim_pred_weight': (192L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:54:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 141, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 303L, 1000L),
 'dim_pred_bias': (84L,),
 'dim_pred_weight': (84L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:55:29] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 141, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (84L,),
 'dim_pred_weight': (84L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:56:13] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 141, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 90, in train_net
    arg_params['dim_pred_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['dim_pred_weight'])
KeyError: 'dim_pred_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 90, in train_net
    arg_params['dim_pred_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['dim_pred_weight'])
KeyError: 'dim_pred_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 256L, 42L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 90, in train_net
    arg_params['dim_pred_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['dim_pred_weight'])
KeyError: 'dim_pred_weight'
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 411, in get_vgg_train
    group = mx.symbol.Group([rpn_cls_prob, rpn_bbox_loss, cls_prob, bbox_loss, dim_loss, mx.symbol.BlockGrad(label)])
NameError: global name 'dim_loss' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_reshape_output': (1L, 128L, 21L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 90, in train_net
    arg_params['dim_pred_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['dim_pred_weight'])
KeyError: 'dim_pred_weight'
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_reshape_output': (1L, 128L, 21L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[06:04:52] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 143, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_output': (128L, 21L),
 'cls_prob_output': (128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 10L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 99, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: cla_score_weight not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_output': (128L, 21L),
 'cls_prob_output': (128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 101, in train_net
    'shape inconsistent for ' + k + ' inferred ' + str(arg_shape_dict[k]) + ' provided ' + str(arg_params[k].shape)
AssertionError: shape inconsistent for cls_score_weight inferred (21L, 4096L) provided (4L, 4096L)
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[06:09:20] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 143, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 35, in update
    label = preds[4]
IndexError: list index out of range
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 125, in train_net
    for child_metric in [rpn_eval_metric, rpn_cls_metric, rpn_bbox_metric, eval_metric, cls_metric, bbox_metric]:
NameError: global name 'cls_metric' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 9L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[06:10:53] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 143, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 35, in update
    label = preds[4]
IndexError: list index out of range
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[06:12:41] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 1.75 samples/sec	Train-RPNAcc=0.528088,	RPNLogLoss=0.698119,	RPNL1Loss=0.528275,	RCNNAcc=0.216890,	RCNNLogLoss=2.815311,	RCNNL1Loss=0.333119,	
INFO:root:Epoch[1] Batch [40]	Speed: 2.08 samples/sec	Train-RPNAcc=0.553925,	RPNLogLoss=0.694271,	RPNL1Loss=0.480089,	RCNNAcc=0.512005,	RCNNLogLoss=2.183552,	RCNNL1Loss=0.328711,	
INFO:root:Epoch[1] Batch [60]	Speed: 2.11 samples/sec	Train-RPNAcc=0.578061,	RPNLogLoss=0.690679,	RPNL1Loss=0.451139,	RCNNAcc=0.622182,	RCNNLogLoss=1.792579,	RCNNL1Loss=0.346453,	
INFO:root:Epoch[1] Batch [80]	Speed: 1.20 samples/sec	Train-RPNAcc=0.593268,	RPNLogLoss=0.687017,	RPNL1Loss=0.476895,	RCNNAcc=0.680170,	RCNNLogLoss=1.526412,	RCNNL1Loss=0.347327,	
INFO:root:Epoch[1] Batch [100]	Speed: 2.00 samples/sec	Train-RPNAcc=0.607132,	RPNLogLoss=0.683068,	RPNL1Loss=0.490559,	RCNNAcc=0.713335,	RCNNLogLoss=1.353403,	RCNNL1Loss=0.354578,	
INFO:root:Epoch[1] Batch [120]	Speed: 2.04 samples/sec	Train-RPNAcc=0.619512,	RPNLogLoss=0.677451,	RPNL1Loss=0.486376,	RCNNAcc=0.746191,	RCNNLogLoss=1.188653,	RCNNL1Loss=0.332285,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.82 samples/sec	Train-RPNAcc=0.631704,	RPNLogLoss=0.671654,	RPNL1Loss=0.483928,	RCNNAcc=0.762134,	RCNNLogLoss=1.087841,	RCNNL1Loss=0.338840,	
INFO:root:Epoch[1] Batch [160]	Speed: 1.80 samples/sec	Train-RPNAcc=0.642736,	RPNLogLoss=0.664337,	RPNL1Loss=0.477923,	RCNNAcc=0.775184,	RCNNLogLoss=1.001010,	RCNNL1Loss=0.346939,	
INFO:root:Epoch[1] Batch [180]	Speed: 1.91 samples/sec	Train-RPNAcc=0.653962,	RPNLogLoss=0.656225,	RPNL1Loss=0.460569,	RCNNAcc=0.791091,	RCNNLogLoss=0.921449,	RCNNL1Loss=0.342319,	
INFO:root:Epoch[1] Batch [200]	Speed: 1.48 samples/sec	Train-RPNAcc=0.664548,	RPNLogLoss=0.647019,	RPNL1Loss=0.449221,	RCNNAcc=0.802433,	RCNNLogLoss=0.856279,	RCNNL1Loss=0.338623,	
INFO:root:Epoch[1] Batch [220]	Speed: 1.79 samples/sec	Train-RPNAcc=0.675675,	RPNLogLoss=0.636533,	RPNL1Loss=0.437354,	RCNNAcc=0.812995,	RCNNLogLoss=0.800902,	RCNNL1Loss=0.332215,	
INFO:root:Epoch[1] Batch [240]	Speed: 1.75 samples/sec	Train-RPNAcc=0.685263,	RPNLogLoss=0.625375,	RPNL1Loss=0.426894,	RCNNAcc=0.821966,	RCNNLogLoss=0.753539,	RCNNL1Loss=0.324324,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.98 samples/sec	Train-RPNAcc=0.693487,	RPNLogLoss=0.613790,	RPNL1Loss=0.413699,	RCNNAcc=0.826509,	RCNNLogLoss=0.723428,	RCNNL1Loss=0.330306,	
INFO:root:Epoch[1] Batch [280]	Speed: 1.33 samples/sec	Train-RPNAcc=0.701262,	RPNLogLoss=0.602373,	RPNL1Loss=0.402557,	RCNNAcc=0.829877,	RCNNLogLoss=0.696764,	RCNNL1Loss=0.333407,	
INFO:root:Epoch[1] Batch [300]	Speed: 1.74 samples/sec	Train-RPNAcc=0.708576,	RPNLogLoss=0.590510,	RPNL1Loss=0.390707,	RCNNAcc=0.833056,	RCNNLogLoss=0.673861,	RCNNL1Loss=0.337512,	
INFO:root:Epoch[1] Batch [320]	Speed: 1.81 samples/sec	Train-RPNAcc=0.716791,	RPNLogLoss=0.577697,	RPNL1Loss=0.380555,	RCNNAcc=0.836522,	RCNNLogLoss=0.652028,	RCNNL1Loss=0.337176,	
INFO:root:Epoch[1] Batch [340]	Speed: 1.76 samples/sec	Train-RPNAcc=0.722817,	RPNLogLoss=0.566772,	RPNL1Loss=0.373467,	RCNNAcc=0.841138,	RCNNLogLoss=0.628412,	RCNNL1Loss=0.330496,	
INFO:root:Epoch[1] Batch [360]	Speed: 1.76 samples/sec	Train-RPNAcc=0.728056,	RPNLogLoss=0.556130,	RPNL1Loss=0.364067,	RCNNAcc=0.843620,	RCNNLogLoss=0.610527,	RCNNL1Loss=0.332358,	
INFO:root:Epoch[1] Batch [380]	Speed: 1.43 samples/sec	Train-RPNAcc=0.733175,	RPNLogLoss=0.546849,	RPNL1Loss=0.356007,	RCNNAcc=0.846580,	RCNNLogLoss=0.593685,	RCNNL1Loss=0.332588,	
INFO:root:Epoch[1] Batch [400]	Speed: 0.87 samples/sec	Train-RPNAcc=0.738320,	RPNLogLoss=0.538004,	RPNL1Loss=0.348420,	RCNNAcc=0.848250,	RCNNLogLoss=0.582587,	RCNNL1Loss=0.335248,	
INFO:root:Epoch[1] Batch [420]	Speed: 1.73 samples/sec	Train-RPNAcc=0.743050,	RPNLogLoss=0.529190,	RPNL1Loss=0.339941,	RCNNAcc=0.849688,	RCNNLogLoss=0.571061,	RCNNL1Loss=0.339609,	
INFO:root:Epoch[1] Batch [440]	Speed: 1.64 samples/sec	Train-RPNAcc=0.745412,	RPNLogLoss=0.522367,	RPNL1Loss=0.335550,	RCNNAcc=0.851811,	RCNNLogLoss=0.558491,	RCNNL1Loss=0.340335,	
INFO:root:Epoch[1] Batch [460]	Speed: 1.53 samples/sec	Train-RPNAcc=0.750136,	RPNLogLoss=0.514387,	RPNL1Loss=0.329051,	RCNNAcc=0.853918,	RCNNLogLoss=0.545997,	RCNNL1Loss=0.340370,	
INFO:root:Epoch[1] Batch [480]	Speed: 1.75 samples/sec	Train-RPNAcc=0.753703,	RPNLogLoss=0.507898,	RPNL1Loss=0.325350,	RCNNAcc=0.854908,	RCNNLogLoss=0.536762,	RCNNL1Loss=0.343565,	
INFO:root:Epoch[1] Batch [500]	Speed: 1.54 samples/sec	Train-RPNAcc=0.759177,	RPNLogLoss=0.499948,	RPNL1Loss=0.317984,	RCNNAcc=0.856584,	RCNNLogLoss=0.526631,	RCNNL1Loss=0.342972,	
INFO:root:Epoch[1] Batch [520]	Speed: 1.07 samples/sec	Train-RPNAcc=0.762011,	RPNLogLoss=0.494606,	RPNL1Loss=0.312340,	RCNNAcc=0.857576,	RCNNLogLoss=0.518370,	RCNNL1Loss=0.342707,	
INFO:root:Epoch[1] Batch [540]	Speed: 1.76 samples/sec	Train-RPNAcc=0.763553,	RPNLogLoss=0.490015,	RPNL1Loss=0.308726,	RCNNAcc=0.858711,	RCNNLogLoss=0.510309,	RCNNL1Loss=0.342973,	
INFO:root:Epoch[1] Batch [560]	Speed: 1.85 samples/sec	Train-RPNAcc=0.767470,	RPNLogLoss=0.483273,	RPNL1Loss=0.301887,	RCNNAcc=0.860712,	RCNNLogLoss=0.500116,	RCNNL1Loss=0.339140,	
INFO:root:Epoch[1] Batch [580]	Speed: 1.57 samples/sec	Train-RPNAcc=0.769652,	RPNLogLoss=0.478598,	RPNL1Loss=0.297978,	RCNNAcc=0.861419,	RCNNLogLoss=0.493298,	RCNNL1Loss=0.339876,	
INFO:root:Epoch[1] Batch [600]	Speed: 1.82 samples/sec	Train-RPNAcc=0.771975,	RPNLogLoss=0.473464,	RPNL1Loss=0.293995,	RCNNAcc=0.862664,	RCNNLogLoss=0.485793,	RCNNL1Loss=0.340980,	
INFO:root:Epoch[1] Batch [620]	Speed: 1.66 samples/sec	Train-RPNAcc=0.774136,	RPNLogLoss=0.468708,	RPNL1Loss=0.289560,	RCNNAcc=0.863149,	RCNNLogLoss=0.480484,	RCNNL1Loss=0.345929,	
INFO:root:Epoch[1] Batch [640]	Speed: 0.79 samples/sec	Train-RPNAcc=0.775345,	RPNLogLoss=0.465040,	RPNL1Loss=0.286698,	RCNNAcc=0.864092,	RCNNLogLoss=0.474290,	RCNNL1Loss=0.346678,	
INFO:root:Epoch[1] Batch [660]	Speed: 1.60 samples/sec	Train-RPNAcc=0.777622,	RPNLogLoss=0.460434,	RPNL1Loss=0.284302,	RCNNAcc=0.865426,	RCNNLogLoss=0.467594,	RCNNL1Loss=0.347188,	
INFO:root:Epoch[1] Batch [680]	Speed: 1.77 samples/sec	Train-RPNAcc=0.779799,	RPNLogLoss=0.456408,	RPNL1Loss=0.281549,	RCNNAcc=0.867050,	RCNNLogLoss=0.460143,	RCNNL1Loss=0.344728,	
INFO:root:Epoch[1] Batch [700]	Speed: 1.62 samples/sec	Train-RPNAcc=0.781384,	RPNLogLoss=0.453177,	RPNL1Loss=0.278889,	RCNNAcc=0.867956,	RCNNLogLoss=0.455373,	RCNNL1Loss=0.344091,	
INFO:root:Epoch[1] Batch [720]	Speed: 1.67 samples/sec	Train-RPNAcc=0.783921,	RPNLogLoss=0.449334,	RPNL1Loss=0.276101,	RCNNAcc=0.868737,	RCNNLogLoss=0.450366,	RCNNL1Loss=0.343382,	
INFO:root:Epoch[1] Batch [740]	Speed: 1.53 samples/sec	Train-RPNAcc=0.786411,	RPNLogLoss=0.445782,	RPNL1Loss=0.272999,	RCNNAcc=0.869591,	RCNNLogLoss=0.445395,	RCNNL1Loss=0.343421,	
INFO:root:Epoch[1] Batch [760]	Speed: 0.87 samples/sec	Train-RPNAcc=0.787769,	RPNLogLoss=0.442679,	RPNL1Loss=0.269822,	RCNNAcc=0.870267,	RCNNLogLoss=0.440776,	RCNNL1Loss=0.343741,	
INFO:root:Epoch[1] Batch [780]	Speed: 1.68 samples/sec	Train-RPNAcc=0.789713,	RPNLogLoss=0.439637,	RPNL1Loss=0.267242,	RCNNAcc=0.870869,	RCNNLogLoss=0.435923,	RCNNL1Loss=0.345248,	
INFO:root:Epoch[1] Batch [800]	Speed: 1.76 samples/sec	Train-RPNAcc=0.791842,	RPNLogLoss=0.436508,	RPNL1Loss=0.265323,	RCNNAcc=0.872015,	RCNNLogLoss=0.430481,	RCNNL1Loss=0.345463,	
INFO:root:Epoch[1] Batch [820]	Speed: 1.59 samples/sec	Train-RPNAcc=0.794134,	RPNLogLoss=0.433117,	RPNL1Loss=0.263723,	RCNNAcc=0.873325,	RCNNLogLoss=0.424688,	RCNNL1Loss=0.344274,	
INFO:root:Epoch[1] Batch [840]	Speed: 1.68 samples/sec	Train-RPNAcc=0.795937,	RPNLogLoss=0.430170,	RPNL1Loss=0.261488,	RCNNAcc=0.874108,	RCNNLogLoss=0.420124,	RCNNL1Loss=0.343814,	
INFO:root:Epoch[1] Batch [860]	Speed: 1.26 samples/sec	Train-RPNAcc=0.797646,	RPNLogLoss=0.427808,	RPNL1Loss=0.260210,	RCNNAcc=0.874891,	RCNNLogLoss=0.416298,	RCNNL1Loss=0.342630,	
INFO:root:Epoch[1] Batch [880]	Speed: 0.93 samples/sec	Train-RPNAcc=0.799291,	RPNLogLoss=0.425131,	RPNL1Loss=0.258071,	RCNNAcc=0.875452,	RCNNLogLoss=0.412811,	RCNNL1Loss=0.343740,	
INFO:root:Epoch[1] Batch [900]	Speed: 1.62 samples/sec	Train-RPNAcc=0.801510,	RPNLogLoss=0.422544,	RPNL1Loss=0.256793,	RCNNAcc=0.876318,	RCNNLogLoss=0.408828,	RCNNL1Loss=0.343207,	
INFO:root:Epoch[1] Batch [920]	Speed: 1.66 samples/sec	Train-RPNAcc=0.802673,	RPNLogLoss=0.420217,	RPNL1Loss=0.255070,	RCNNAcc=0.876976,	RCNNLogLoss=0.405210,	RCNNL1Loss=0.342202,	
INFO:root:Epoch[1] Batch [940]	Speed: 1.43 samples/sec	Train-RPNAcc=0.803899,	RPNLogLoss=0.417893,	RPNL1Loss=0.253792,	RCNNAcc=0.877408,	RCNNLogLoss=0.402108,	RCNNL1Loss=0.343080,	
INFO:root:Epoch[1] Batch [960]	Speed: 1.33 samples/sec	Train-RPNAcc=0.805379,	RPNLogLoss=0.415062,	RPNL1Loss=0.252193,	RCNNAcc=0.878512,	RCNNLogLoss=0.397422,	RCNNL1Loss=0.341449,	
INFO:root:Epoch[1] Batch [980]	Speed: 0.88 samples/sec	Train-RPNAcc=0.807073,	RPNLogLoss=0.412100,	RPNL1Loss=0.249904,	RCNNAcc=0.879786,	RCNNLogLoss=0.392663,	RCNNL1Loss=0.339839,	
INFO:root:Epoch[1] Batch [1000]	Speed: 1.54 samples/sec	Train-RPNAcc=0.808660,	RPNLogLoss=0.409205,	RPNL1Loss=0.247398,	RCNNAcc=0.880510,	RCNNLogLoss=0.389273,	RCNNL1Loss=0.339683,	
INFO:root:Epoch[1] Batch [1020]	Speed: 1.51 samples/sec	Train-RPNAcc=0.809466,	RPNLogLoss=0.407830,	RPNL1Loss=0.246885,	RCNNAcc=0.880708,	RCNNLogLoss=0.387089,	RCNNL1Loss=0.341403,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [1040]	Speed: 1.43 samples/sec	Train-RPNAcc=0.810710,	RPNLogLoss=0.405945,	RPNL1Loss=0.245965,	RCNNAcc=0.881462,	RCNNLogLoss=0.383729,	RCNNL1Loss=0.341026,	
INFO:root:Epoch[1] Batch [1060]	Speed: 1.48 samples/sec	Train-RPNAcc=0.811716,	RPNLogLoss=0.404196,	RPNL1Loss=0.244962,	RCNNAcc=0.881774,	RCNNLogLoss=0.381197,	RCNNL1Loss=0.341660,	
INFO:root:Epoch[1] Batch [1080]	Speed: 1.42 samples/sec	Train-RPNAcc=0.812944,	RPNLogLoss=0.401941,	RPNL1Loss=0.243458,	RCNNAcc=0.882003,	RCNNLogLoss=0.379058,	RCNNL1Loss=0.341978,	
INFO:root:Epoch[1] Batch [1100]	Speed: 1.55 samples/sec	Train-RPNAcc=0.813728,	RPNLogLoss=0.400565,	RPNL1Loss=0.243246,	RCNNAcc=0.882131,	RCNNLogLoss=0.377139,	RCNNL1Loss=0.343286,	
INFO:root:Epoch[1] Batch [1120]	Speed: 1.60 samples/sec	Train-RPNAcc=0.814967,	RPNLogLoss=0.398307,	RPNL1Loss=0.241927,	RCNNAcc=0.883036,	RCNNLogLoss=0.373690,	RCNNL1Loss=0.342116,	
INFO:root:Epoch[1] Batch [1140]	Speed: 0.86 samples/sec	Train-RPNAcc=0.816191,	RPNLogLoss=0.396180,	RPNL1Loss=0.240012,	RCNNAcc=0.883887,	RCNNLogLoss=0.370209,	RCNNL1Loss=0.341332,	
INFO:root:Epoch[1] Batch [1160]	Speed: 1.03 samples/sec	Train-RPNAcc=0.817160,	RPNLogLoss=0.394465,	RPNL1Loss=0.239463,	RCNNAcc=0.884569,	RCNNLogLoss=0.367293,	RCNNL1Loss=0.340552,	
INFO:root:Epoch[1] Batch [1180]	Speed: 1.55 samples/sec	Train-RPNAcc=0.818421,	RPNLogLoss=0.392642,	RPNL1Loss=0.238426,	RCNNAcc=0.885174,	RCNNLogLoss=0.364806,	RCNNL1Loss=0.340150,	
INFO:root:Epoch[1] Batch [1200]	Speed: 1.57 samples/sec	Train-RPNAcc=0.819226,	RPNLogLoss=0.391184,	RPNL1Loss=0.237060,	RCNNAcc=0.885369,	RCNNLogLoss=0.363065,	RCNNL1Loss=0.340340,	
INFO:root:Epoch[1] Batch [1220]	Speed: 1.62 samples/sec	Train-RPNAcc=0.820418,	RPNLogLoss=0.389302,	RPNL1Loss=0.235629,	RCNNAcc=0.885769,	RCNNLogLoss=0.361052,	RCNNL1Loss=0.340774,	
INFO:root:Epoch[1] Batch [1240]	Speed: 1.29 samples/sec	Train-RPNAcc=0.821468,	RPNLogLoss=0.387448,	RPNL1Loss=0.233574,	RCNNAcc=0.886011,	RCNNLogLoss=0.359187,	RCNNL1Loss=0.340728,	
INFO:root:Epoch[1] Batch [1260]	Speed: 1.00 samples/sec	Train-RPNAcc=0.822242,	RPNLogLoss=0.386031,	RPNL1Loss=0.232760,	RCNNAcc=0.886164,	RCNNLogLoss=0.357618,	RCNNL1Loss=0.340682,	
INFO:root:Epoch[1] Batch [1280]	Speed: 1.64 samples/sec	Train-RPNAcc=0.823328,	RPNLogLoss=0.384290,	RPNL1Loss=0.232030,	RCNNAcc=0.886758,	RCNNLogLoss=0.355024,	RCNNL1Loss=0.340392,	
INFO:root:Epoch[1] Batch [1300]	Speed: 1.58 samples/sec	Train-RPNAcc=0.824261,	RPNLogLoss=0.382668,	RPNL1Loss=0.230853,	RCNNAcc=0.887076,	RCNNLogLoss=0.352901,	RCNNL1Loss=0.340027,	
INFO:root:Epoch[1] Batch [1320]	Speed: 1.42 samples/sec	Train-RPNAcc=0.825396,	RPNLogLoss=0.380627,	RPNL1Loss=0.229299,	RCNNAcc=0.887869,	RCNNLogLoss=0.349916,	RCNNL1Loss=0.338654,	
INFO:root:Epoch[1] Batch [1340]	Speed: 1.59 samples/sec	Train-RPNAcc=0.826255,	RPNLogLoss=0.379129,	RPNL1Loss=0.228537,	RCNNAcc=0.888172,	RCNNLogLoss=0.348250,	RCNNL1Loss=0.338991,	
INFO:root:Epoch[1] Batch [1360]	Speed: 1.52 samples/sec	Train-RPNAcc=0.827189,	RPNLogLoss=0.377611,	RPNL1Loss=0.227887,	RCNNAcc=0.888604,	RCNNLogLoss=0.346188,	RCNNL1Loss=0.338991,	
INFO:root:Epoch[1] Batch [1380]	Speed: 1.51 samples/sec	Train-RPNAcc=0.827978,	RPNLogLoss=0.376282,	RPNL1Loss=0.227075,	RCNNAcc=0.888803,	RCNNLogLoss=0.344801,	RCNNL1Loss=0.339766,	
INFO:root:Epoch[1] Batch [1400]	Speed: 1.34 samples/sec	Train-RPNAcc=0.829201,	RPNLogLoss=0.374251,	RPNL1Loss=0.225452,	RCNNAcc=0.889354,	RCNNLogLoss=0.342489,	RCNNL1Loss=0.339169,	
INFO:root:Epoch[1] Batch [1420]	Speed: 1.01 samples/sec	Train-RPNAcc=0.830085,	RPNLogLoss=0.372584,	RPNL1Loss=0.224109,	RCNNAcc=0.889657,	RCNNLogLoss=0.341111,	RCNNL1Loss=0.338612,	
INFO:root:Epoch[1] Batch [1440]	Speed: 1.54 samples/sec	Train-RPNAcc=0.830866,	RPNLogLoss=0.370939,	RPNL1Loss=0.223225,	RCNNAcc=0.890175,	RCNNLogLoss=0.339207,	RCNNL1Loss=0.337731,	
INFO:root:Epoch[1] Batch [1460]	Speed: 1.44 samples/sec	Train-RPNAcc=0.831783,	RPNLogLoss=0.369276,	RPNL1Loss=0.222293,	RCNNAcc=0.890727,	RCNNLogLoss=0.336934,	RCNNL1Loss=0.337320,	
INFO:root:Epoch[1] Batch [1480]	Speed: 1.28 samples/sec	Train-RPNAcc=0.832382,	RPNLogLoss=0.368223,	RPNL1Loss=0.221687,	RCNNAcc=0.891005,	RCNNLogLoss=0.335392,	RCNNL1Loss=0.337054,	
INFO:root:Epoch[1] Batch [1500]	Speed: 1.59 samples/sec	Train-RPNAcc=0.832802,	RPNLogLoss=0.367148,	RPNL1Loss=0.220880,	RCNNAcc=0.891296,	RCNNLogLoss=0.333880,	RCNNL1Loss=0.336962,	
INFO:root:Epoch[1] Batch [1520]	Speed: 1.59 samples/sec	Train-RPNAcc=0.833734,	RPNLogLoss=0.365357,	RPNL1Loss=0.219629,	RCNNAcc=0.891837,	RCNNLogLoss=0.331842,	RCNNL1Loss=0.336366,	
INFO:root:Epoch[1] Batch [1540]	Speed: 1.44 samples/sec	Train-RPNAcc=0.834528,	RPNLogLoss=0.363932,	RPNL1Loss=0.219124,	RCNNAcc=0.892181,	RCNNLogLoss=0.330400,	RCNNL1Loss=0.336571,	
INFO:root:Epoch[1] Batch [1560]	Speed: 1.44 samples/sec	Train-RPNAcc=0.835264,	RPNLogLoss=0.362586,	RPNL1Loss=0.218190,	RCNNAcc=0.892472,	RCNNLogLoss=0.328931,	RCNNL1Loss=0.336608,	
INFO:root:Epoch[1] Batch [1580]	Speed: 0.84 samples/sec	Train-RPNAcc=0.835900,	RPNLogLoss=0.360915,	RPNL1Loss=0.216716,	RCNNAcc=0.892948,	RCNNLogLoss=0.327048,	RCNNL1Loss=0.336295,	
INFO:root:Epoch[1] Batch [1600]	Speed: 1.64 samples/sec	Train-RPNAcc=0.836821,	RPNLogLoss=0.359375,	RPNL1Loss=0.215792,	RCNNAcc=0.893104,	RCNNLogLoss=0.326863,	RCNNL1Loss=0.336607,	
INFO:root:Epoch[1] Batch [1620]	Speed: 1.52 samples/sec	Train-RPNAcc=0.837379,	RPNLogLoss=0.358212,	RPNL1Loss=0.214872,	RCNNAcc=0.893531,	RCNNLogLoss=0.325302,	RCNNL1Loss=0.336504,	
INFO:root:Epoch[1] Batch [1640]	Speed: 1.42 samples/sec	Train-RPNAcc=0.838061,	RPNLogLoss=0.356667,	RPNL1Loss=0.213541,	RCNNAcc=0.893891,	RCNNLogLoss=0.323750,	RCNNL1Loss=0.336407,	
INFO:root:Epoch[1] Batch [1660]	Speed: 1.61 samples/sec	Train-RPNAcc=0.838736,	RPNLogLoss=0.355487,	RPNL1Loss=0.212760,	RCNNAcc=0.894280,	RCNNLogLoss=0.322479,	RCNNL1Loss=0.336649,	
INFO:root:Epoch[1] Batch [1680]	Speed: 1.34 samples/sec	Train-RPNAcc=0.839446,	RPNLogLoss=0.354252,	RPNL1Loss=0.211637,	RCNNAcc=0.894552,	RCNNLogLoss=0.321161,	RCNNL1Loss=0.336880,	
INFO:root:Epoch[1] Batch [1700]	Speed: 0.98 samples/sec	Train-RPNAcc=0.839775,	RPNLogLoss=0.353508,	RPNL1Loss=0.210856,	RCNNAcc=0.894460,	RCNNLogLoss=0.320676,	RCNNL1Loss=0.337742,	
INFO:root:Epoch[1] Batch [1720]	Speed: 1.34 samples/sec	Train-RPNAcc=0.840432,	RPNLogLoss=0.352351,	RPNL1Loss=0.210036,	RCNNAcc=0.894851,	RCNNLogLoss=0.319523,	RCNNL1Loss=0.337664,	
INFO:root:Epoch[1] Batch [1740]	Speed: 1.57 samples/sec	Train-RPNAcc=0.841080,	RPNLogLoss=0.351160,	RPNL1Loss=0.209197,	RCNNAcc=0.894991,	RCNNLogLoss=0.318571,	RCNNL1Loss=0.337658,	
INFO:root:Epoch[1] Batch [1760]	Speed: 1.48 samples/sec	Train-RPNAcc=0.841609,	RPNLogLoss=0.350058,	RPNL1Loss=0.208123,	RCNNAcc=0.895053,	RCNNLogLoss=0.317558,	RCNNL1Loss=0.337894,	
INFO:root:Epoch[1] Batch [1780]	Speed: 1.61 samples/sec	Train-RPNAcc=0.841993,	RPNLogLoss=0.349276,	RPNL1Loss=0.207505,	RCNNAcc=0.895209,	RCNNLogLoss=0.316491,	RCNNL1Loss=0.337617,	
INFO:root:Epoch[1] Batch [1800]	Speed: 1.62 samples/sec	Train-RPNAcc=0.842492,	RPNLogLoss=0.348243,	RPNL1Loss=0.206908,	RCNNAcc=0.895267,	RCNNLogLoss=0.316102,	RCNNL1Loss=0.338160,	
INFO:root:Epoch[1] Batch [1820]	Speed: 0.87 samples/sec	Train-RPNAcc=0.842892,	RPNLogLoss=0.347362,	RPNL1Loss=0.206205,	RCNNAcc=0.895482,	RCNNLogLoss=0.315083,	RCNNL1Loss=0.338098,	
INFO:root:Epoch[1] Batch [1840]	Speed: 1.42 samples/sec	Train-RPNAcc=0.843633,	RPNLogLoss=0.345903,	RPNL1Loss=0.205032,	RCNNAcc=0.895879,	RCNNLogLoss=0.313857,	RCNNL1Loss=0.337369,	
INFO:root:Epoch[1] Batch [1860]	Speed: 1.61 samples/sec	Train-RPNAcc=0.843897,	RPNLogLoss=0.345120,	RPNL1Loss=0.204410,	RCNNAcc=0.896112,	RCNNLogLoss=0.312802,	RCNNL1Loss=0.337413,	
INFO:root:Epoch[1] Batch [1880]	Speed: 1.46 samples/sec	Train-RPNAcc=0.844547,	RPNLogLoss=0.343946,	RPNL1Loss=0.203889,	RCNNAcc=0.896294,	RCNNLogLoss=0.311675,	RCNNL1Loss=0.337687,	
INFO:root:Epoch[1] Batch [1900]	Speed: 1.72 samples/sec	Train-RPNAcc=0.845227,	RPNLogLoss=0.342560,	RPNL1Loss=0.203014,	RCNNAcc=0.896674,	RCNNLogLoss=0.310355,	RCNNL1Loss=0.337110,	
INFO:root:Epoch[1] Batch [1920]	Speed: 1.18 samples/sec	Train-RPNAcc=0.845525,	RPNLogLoss=0.341914,	RPNL1Loss=0.202376,	RCNNAcc=0.896754,	RCNNLogLoss=0.309842,	RCNNL1Loss=0.337453,	
INFO:root:Epoch[1] Batch [1940]	Speed: 1.14 samples/sec	Train-RPNAcc=0.845956,	RPNLogLoss=0.340887,	RPNL1Loss=0.201664,	RCNNAcc=0.897029,	RCNNLogLoss=0.308799,	RCNNL1Loss=0.337300,	
INFO:root:Epoch[1] Batch [1960]	Speed: 1.53 samples/sec	Train-RPNAcc=0.846624,	RPNLogLoss=0.339732,	RPNL1Loss=0.201309,	RCNNAcc=0.897290,	RCNNLogLoss=0.307730,	RCNNL1Loss=0.337394,	
INFO:root:Epoch[1] Batch [1980]	Speed: 1.31 samples/sec	Train-RPNAcc=0.847201,	RPNLogLoss=0.338680,	RPNL1Loss=0.200756,	RCNNAcc=0.897617,	RCNNLogLoss=0.306559,	RCNNL1Loss=0.337678,	
INFO:root:Epoch[1] Batch [2000]	Speed: 1.39 samples/sec	Train-RPNAcc=0.847920,	RPNLogLoss=0.337434,	RPNL1Loss=0.200365,	RCNNAcc=0.898028,	RCNNLogLoss=0.305282,	RCNNL1Loss=0.337563,	
INFO:root:Epoch[1] Batch [2020]	Speed: 1.64 samples/sec	Train-RPNAcc=0.848261,	RPNLogLoss=0.336528,	RPNL1Loss=0.199694,	RCNNAcc=0.898198,	RCNNLogLoss=0.304371,	RCNNL1Loss=0.337458,	
INFO:root:Epoch[1] Batch [2040]	Speed: 1.13 samples/sec	Train-RPNAcc=0.848939,	RPNLogLoss=0.335243,	RPNL1Loss=0.198846,	RCNNAcc=0.898564,	RCNNLogLoss=0.303129,	RCNNL1Loss=0.337193,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [2060]	Speed: 1.62 samples/sec	Train-RPNAcc=0.849392,	RPNLogLoss=0.334270,	RPNL1Loss=0.198032,	RCNNAcc=0.898676,	RCNNLogLoss=0.302587,	RCNNL1Loss=0.337569,	
INFO:root:Epoch[1] Batch [2080]	Speed: 1.61 samples/sec	Train-RPNAcc=0.849871,	RPNLogLoss=0.333377,	RPNL1Loss=0.197706,	RCNNAcc=0.898944,	RCNNLogLoss=0.301721,	RCNNL1Loss=0.337318,	
INFO:root:Epoch[1] Batch [2100]	Speed: 1.51 samples/sec	Train-RPNAcc=0.850239,	RPNLogLoss=0.332556,	RPNL1Loss=0.197105,	RCNNAcc=0.899058,	RCNNLogLoss=0.301172,	RCNNL1Loss=0.337342,	
INFO:root:Epoch[1] Batch [2120]	Speed: 1.59 samples/sec	Train-RPNAcc=0.850572,	RPNLogLoss=0.331840,	RPNL1Loss=0.196769,	RCNNAcc=0.899064,	RCNNLogLoss=0.301011,	RCNNL1Loss=0.337480,	
INFO:root:Epoch[1] Batch [2140]	Speed: 1.62 samples/sec	Train-RPNAcc=0.851163,	RPNLogLoss=0.330689,	RPNL1Loss=0.196081,	RCNNAcc=0.899415,	RCNNLogLoss=0.300010,	RCNNL1Loss=0.337539,	
INFO:root:Epoch[1] Batch [2160]	Speed: 1.61 samples/sec	Train-RPNAcc=0.851667,	RPNLogLoss=0.329688,	RPNL1Loss=0.195406,	RCNNAcc=0.899721,	RCNNLogLoss=0.298757,	RCNNL1Loss=0.337197,	
INFO:root:Epoch[1] Batch [2180]	Speed: 1.68 samples/sec	Train-RPNAcc=0.851903,	RPNLogLoss=0.328909,	RPNL1Loss=0.195140,	RCNNAcc=0.899860,	RCNNLogLoss=0.298161,	RCNNL1Loss=0.337334,	
INFO:root:Epoch[1] Batch [2200]	Speed: 1.25 samples/sec	Train-RPNAcc=0.852409,	RPNLogLoss=0.327902,	RPNL1Loss=0.194507,	RCNNAcc=0.900067,	RCNNLogLoss=0.297593,	RCNNL1Loss=0.337257,	
INFO:root:Epoch[1] Batch [2220]	Speed: 1.27 samples/sec	Train-RPNAcc=0.852943,	RPNLogLoss=0.326855,	RPNL1Loss=0.193967,	RCNNAcc=0.900263,	RCNNLogLoss=0.296687,	RCNNL1Loss=0.336988,	
INFO:root:Epoch[1] Batch [2240]	Speed: 0.91 samples/sec	Train-RPNAcc=0.853522,	RPNLogLoss=0.325718,	RPNL1Loss=0.193279,	RCNNAcc=0.900623,	RCNNLogLoss=0.295394,	RCNNL1Loss=0.336885,	
INFO:root:Epoch[1] Batch [2260]	Speed: 1.62 samples/sec	Train-RPNAcc=0.854050,	RPNLogLoss=0.324685,	RPNL1Loss=0.192545,	RCNNAcc=0.900797,	RCNNLogLoss=0.294694,	RCNNL1Loss=0.336567,	
INFO:root:Epoch[1] Batch [2280]	Speed: 1.63 samples/sec	Train-RPNAcc=0.854517,	RPNLogLoss=0.323674,	RPNL1Loss=0.191924,	RCNNAcc=0.901112,	RCNNLogLoss=0.293559,	RCNNL1Loss=0.336594,	
INFO:root:Epoch[1] Batch [2300]	Speed: 0.92 samples/sec	Train-RPNAcc=0.854859,	RPNLogLoss=0.322801,	RPNL1Loss=0.191255,	RCNNAcc=0.901184,	RCNNLogLoss=0.293139,	RCNNL1Loss=0.336584,	
INFO:root:Epoch[1] Batch [2320]	Speed: 1.61 samples/sec	Train-RPNAcc=0.855294,	RPNLogLoss=0.321914,	RPNL1Loss=0.190754,	RCNNAcc=0.901356,	RCNNLogLoss=0.292451,	RCNNL1Loss=0.336615,	
INFO:root:Epoch[1] Batch [2340]	Speed: 1.55 samples/sec	Train-RPNAcc=0.855515,	RPNLogLoss=0.321359,	RPNL1Loss=0.190166,	RCNNAcc=0.901491,	RCNNLogLoss=0.291899,	RCNNL1Loss=0.336437,	
INFO:root:Epoch[1] Batch [2360]	Speed: 1.26 samples/sec	Train-RPNAcc=0.856117,	RPNLogLoss=0.320159,	RPNL1Loss=0.189290,	RCNNAcc=0.901687,	RCNNLogLoss=0.291156,	RCNNL1Loss=0.336561,	
INFO:root:Epoch[1] Batch [2380]	Speed: 1.65 samples/sec	Train-RPNAcc=0.856478,	RPNLogLoss=0.319362,	RPNL1Loss=0.188827,	RCNNAcc=0.901853,	RCNNLogLoss=0.290443,	RCNNL1Loss=0.336413,	
INFO:root:Epoch[1] Batch [2400]	Speed: 1.60 samples/sec	Train-RPNAcc=0.856679,	RPNLogLoss=0.318830,	RPNL1Loss=0.188454,	RCNNAcc=0.901961,	RCNNLogLoss=0.289945,	RCNNL1Loss=0.336431,	
INFO:root:Epoch[1] Batch [2420]	Speed: 1.69 samples/sec	Train-RPNAcc=0.856937,	RPNLogLoss=0.318128,	RPNL1Loss=0.187951,	RCNNAcc=0.902174,	RCNNLogLoss=0.289077,	RCNNL1Loss=0.336206,	
INFO:root:Epoch[1] Batch [2440]	Speed: 1.69 samples/sec	Train-RPNAcc=0.857546,	RPNLogLoss=0.317030,	RPNL1Loss=0.187201,	RCNNAcc=0.902525,	RCNNLogLoss=0.287927,	RCNNL1Loss=0.335789,	
INFO:root:Epoch[1] Batch [2460]	Speed: 0.88 samples/sec	Train-RPNAcc=0.857737,	RPNLogLoss=0.316479,	RPNL1Loss=0.186667,	RCNNAcc=0.902415,	RCNNLogLoss=0.287863,	RCNNL1Loss=0.336037,	
INFO:root:Epoch[1] Batch [2480]	Speed: 1.41 samples/sec	Train-RPNAcc=0.858101,	RPNLogLoss=0.315627,	RPNL1Loss=0.186177,	RCNNAcc=0.902471,	RCNNLogLoss=0.287325,	RCNNL1Loss=0.336082,	
INFO:root:Epoch[1] Batch [2500]	Speed: 1.62 samples/sec	Train-RPNAcc=0.858502,	RPNLogLoss=0.314880,	RPNL1Loss=0.186097,	RCNNAcc=0.902548,	RCNNLogLoss=0.286763,	RCNNL1Loss=0.336352,	
INFO:root:Epoch[1] Batch [2520]	Speed: 1.69 samples/sec	Train-RPNAcc=0.859042,	RPNLogLoss=0.313852,	RPNL1Loss=0.185492,	RCNNAcc=0.902745,	RCNNLogLoss=0.285995,	RCNNL1Loss=0.336018,	
INFO:root:Epoch[1] Batch [2540]	Speed: 1.36 samples/sec	Train-RPNAcc=0.859529,	RPNLogLoss=0.312897,	RPNL1Loss=0.184904,	RCNNAcc=0.903000,	RCNNLogLoss=0.285109,	RCNNL1Loss=0.335950,	
INFO:root:Epoch[1] Batch [2560]	Speed: 1.65 samples/sec	Train-RPNAcc=0.859932,	RPNLogLoss=0.312092,	RPNL1Loss=0.184506,	RCNNAcc=0.903041,	RCNNLogLoss=0.285026,	RCNNL1Loss=0.336003,	
INFO:root:Epoch[1] Batch [2580]	Speed: 1.55 samples/sec	Train-RPNAcc=0.860496,	RPNLogLoss=0.310990,	RPNL1Loss=0.184009,	RCNNAcc=0.903335,	RCNNLogLoss=0.284166,	RCNNL1Loss=0.335520,	
INFO:root:Epoch[1] Batch [2600]	Speed: 1.67 samples/sec	Train-RPNAcc=0.860914,	RPNLogLoss=0.310124,	RPNL1Loss=0.183356,	RCNNAcc=0.903391,	RCNNLogLoss=0.283762,	RCNNL1Loss=0.335555,	
INFO:root:Epoch[1] Batch [2620]	Speed: 1.69 samples/sec	Train-RPNAcc=0.861090,	RPNLogLoss=0.309530,	RPNL1Loss=0.183015,	RCNNAcc=0.903454,	RCNNLogLoss=0.283275,	RCNNL1Loss=0.335625,	
INFO:root:Epoch[1] Batch [2640]	Speed: 1.58 samples/sec	Train-RPNAcc=0.861363,	RPNLogLoss=0.308816,	RPNL1Loss=0.182460,	RCNNAcc=0.903597,	RCNNLogLoss=0.282747,	RCNNL1Loss=0.335369,	
INFO:root:Epoch[1] Batch [2660]	Speed: 1.63 samples/sec	Train-RPNAcc=0.861752,	RPNLogLoss=0.307998,	RPNL1Loss=0.182034,	RCNNAcc=0.903752,	RCNNLogLoss=0.282125,	RCNNL1Loss=0.335155,	
INFO:root:Epoch[1] Batch [2680]	Speed: 1.36 samples/sec	Train-RPNAcc=0.862056,	RPNLogLoss=0.307382,	RPNL1Loss=0.181660,	RCNNAcc=0.903837,	RCNNLogLoss=0.281819,	RCNNL1Loss=0.335375,	
INFO:root:Epoch[1] Batch [2700]	Speed: 1.03 samples/sec	Train-RPNAcc=0.862567,	RPNLogLoss=0.306475,	RPNL1Loss=0.181336,	RCNNAcc=0.904072,	RCNNLogLoss=0.281006,	RCNNL1Loss=0.335339,	
INFO:root:Epoch[1] Batch [2720]	Speed: 1.24 samples/sec	Train-RPNAcc=0.862978,	RPNLogLoss=0.305583,	RPNL1Loss=0.180736,	RCNNAcc=0.904312,	RCNNLogLoss=0.280279,	RCNNL1Loss=0.335194,	
INFO:root:Epoch[1] Batch [2740]	Speed: 1.70 samples/sec	Train-RPNAcc=0.863505,	RPNLogLoss=0.304614,	RPNL1Loss=0.180119,	RCNNAcc=0.904571,	RCNNLogLoss=0.279548,	RCNNL1Loss=0.334998,	
INFO:root:Epoch[1] Batch [2760]	Speed: 1.51 samples/sec	Train-RPNAcc=0.863854,	RPNLogLoss=0.303828,	RPNL1Loss=0.179859,	RCNNAcc=0.904702,	RCNNLogLoss=0.279066,	RCNNL1Loss=0.335023,	
INFO:root:Epoch[1] Batch [2780]	Speed: 1.61 samples/sec	Train-RPNAcc=0.864062,	RPNLogLoss=0.303227,	RPNL1Loss=0.179528,	RCNNAcc=0.904739,	RCNNLogLoss=0.278730,	RCNNL1Loss=0.334811,	
INFO:root:Epoch[1] Batch [2800]	Speed: 1.69 samples/sec	Train-RPNAcc=0.864418,	RPNLogLoss=0.302550,	RPNL1Loss=0.179279,	RCNNAcc=0.904816,	RCNNLogLoss=0.278278,	RCNNL1Loss=0.335014,	
INFO:root:Epoch[1] Batch [2820]	Speed: 1.01 samples/sec	Train-RPNAcc=0.864778,	RPNLogLoss=0.301796,	RPNL1Loss=0.178919,	RCNNAcc=0.904918,	RCNNLogLoss=0.277854,	RCNNL1Loss=0.335096,	
INFO:root:Epoch[1] Batch [2840]	Speed: 1.39 samples/sec	Train-RPNAcc=0.865184,	RPNLogLoss=0.300915,	RPNL1Loss=0.178263,	RCNNAcc=0.905219,	RCNNLogLoss=0.276940,	RCNNL1Loss=0.334831,	
INFO:root:Epoch[1] Batch [2860]	Speed: 1.66 samples/sec	Train-RPNAcc=0.865563,	RPNLogLoss=0.300068,	RPNL1Loss=0.177696,	RCNNAcc=0.905483,	RCNNLogLoss=0.276154,	RCNNL1Loss=0.334755,	
INFO:root:Epoch[1] Batch [2880]	Speed: 1.35 samples/sec	Train-RPNAcc=0.865971,	RPNLogLoss=0.299210,	RPNL1Loss=0.177360,	RCNNAcc=0.905713,	RCNNLogLoss=0.275346,	RCNNL1Loss=0.334637,	
INFO:root:Epoch[1] Batch [2900]	Speed: 1.61 samples/sec	Train-RPNAcc=0.866248,	RPNLogLoss=0.298632,	RPNL1Loss=0.177184,	RCNNAcc=0.905865,	RCNNLogLoss=0.274907,	RCNNL1Loss=0.334396,	
INFO:root:Epoch[1] Batch [2920]	Speed: 1.61 samples/sec	Train-RPNAcc=0.866584,	RPNLogLoss=0.297943,	RPNL1Loss=0.177215,	RCNNAcc=0.906052,	RCNNLogLoss=0.274318,	RCNNL1Loss=0.334291,	
INFO:root:Epoch[1] Batch [2940]	Speed: 1.60 samples/sec	Train-RPNAcc=0.866923,	RPNLogLoss=0.297368,	RPNL1Loss=0.177034,	RCNNAcc=0.906048,	RCNNLogLoss=0.274124,	RCNNL1Loss=0.334460,	
INFO:root:Epoch[1] Batch [2960]	Speed: 1.57 samples/sec	Train-RPNAcc=0.867352,	RPNLogLoss=0.296557,	RPNL1Loss=0.176558,	RCNNAcc=0.906253,	RCNNLogLoss=0.273468,	RCNNL1Loss=0.334178,	
INFO:root:Epoch[1] Batch [2980]	Speed: 1.41 samples/sec	Train-RPNAcc=0.867512,	RPNLogLoss=0.296092,	RPNL1Loss=0.176279,	RCNNAcc=0.906378,	RCNNLogLoss=0.272935,	RCNNL1Loss=0.334267,	
INFO:root:Epoch[1] Batch [3000]	Speed: 0.99 samples/sec	Train-RPNAcc=0.867892,	RPNLogLoss=0.295247,	RPNL1Loss=0.175782,	RCNNAcc=0.906622,	RCNNLogLoss=0.272165,	RCNNL1Loss=0.333839,	
INFO:root:Epoch[1] Batch [3020]	Speed: 1.71 samples/sec	Train-RPNAcc=0.868003,	RPNLogLoss=0.294780,	RPNL1Loss=0.175367,	RCNNAcc=0.906648,	RCNNLogLoss=0.271799,	RCNNL1Loss=0.333730,	
INFO:root:Epoch[1] Batch [3040]	Speed: 1.65 samples/sec	Train-RPNAcc=0.868308,	RPNLogLoss=0.294160,	RPNL1Loss=0.175187,	RCNNAcc=0.906718,	RCNNLogLoss=0.271535,	RCNNL1Loss=0.333876,	
INFO:root:Epoch[1] Batch [3060]	Speed: 1.25 samples/sec	Train-RPNAcc=0.868682,	RPNLogLoss=0.293442,	RPNL1Loss=0.174916,	RCNNAcc=0.906888,	RCNNLogLoss=0.270985,	RCNNL1Loss=0.333611,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [3080]	Speed: 1.24 samples/sec	Train-RPNAcc=0.869018,	RPNLogLoss=0.292802,	RPNL1Loss=0.174606,	RCNNAcc=0.907039,	RCNNLogLoss=0.270358,	RCNNL1Loss=0.333499,	
INFO:root:Epoch[1] Batch [3100]	Speed: 1.63 samples/sec	Train-RPNAcc=0.869371,	RPNLogLoss=0.292032,	RPNL1Loss=0.174278,	RCNNAcc=0.907202,	RCNNLogLoss=0.269941,	RCNNL1Loss=0.333172,	
INFO:root:Epoch[1] Batch [3120]	Speed: 1.68 samples/sec	Train-RPNAcc=0.869733,	RPNLogLoss=0.291295,	RPNL1Loss=0.173858,	RCNNAcc=0.907344,	RCNNLogLoss=0.269466,	RCNNL1Loss=0.333025,	
INFO:root:Epoch[1] Batch [3140]	Speed: 1.67 samples/sec	Train-RPNAcc=0.870045,	RPNLogLoss=0.290595,	RPNL1Loss=0.173325,	RCNNAcc=0.907558,	RCNNLogLoss=0.268824,	RCNNL1Loss=0.332872,	
INFO:root:Epoch[1] Batch [3160]	Speed: 1.68 samples/sec	Train-RPNAcc=0.870379,	RPNLogLoss=0.289892,	RPNL1Loss=0.172890,	RCNNAcc=0.907728,	RCNNLogLoss=0.268231,	RCNNL1Loss=0.332308,	
INFO:root:Epoch[1] Batch [3180]	Speed: 1.43 samples/sec	Train-RPNAcc=0.870684,	RPNLogLoss=0.289190,	RPNL1Loss=0.172406,	RCNNAcc=0.907962,	RCNNLogLoss=0.267521,	RCNNL1Loss=0.331841,	
INFO:root:Epoch[1] Batch [3200]	Speed: 1.08 samples/sec	Train-RPNAcc=0.870992,	RPNLogLoss=0.288463,	RPNL1Loss=0.171925,	RCNNAcc=0.908066,	RCNNLogLoss=0.267057,	RCNNL1Loss=0.331671,	
INFO:root:Epoch[1] Batch [3220]	Speed: 1.63 samples/sec	Train-RPNAcc=0.871186,	RPNLogLoss=0.287998,	RPNL1Loss=0.171842,	RCNNAcc=0.908212,	RCNNLogLoss=0.266606,	RCNNL1Loss=0.331590,	
INFO:root:Epoch[1] Batch [3240]	Speed: 1.64 samples/sec	Train-RPNAcc=0.871455,	RPNLogLoss=0.287409,	RPNL1Loss=0.171654,	RCNNAcc=0.908297,	RCNNLogLoss=0.266235,	RCNNL1Loss=0.331870,	
INFO:root:Epoch[1] Batch [3260]	Speed: 1.54 samples/sec	Train-RPNAcc=0.871773,	RPNLogLoss=0.286712,	RPNL1Loss=0.171236,	RCNNAcc=0.908418,	RCNNLogLoss=0.265806,	RCNNL1Loss=0.331807,	
INFO:root:Epoch[1] Batch [3280]	Speed: 1.68 samples/sec	Train-RPNAcc=0.872037,	RPNLogLoss=0.286112,	RPNL1Loss=0.170828,	RCNNAcc=0.908576,	RCNNLogLoss=0.265309,	RCNNL1Loss=0.331733,	
INFO:root:Epoch[1] Batch [3300]	Speed: 1.56 samples/sec	Train-RPNAcc=0.872296,	RPNLogLoss=0.285489,	RPNL1Loss=0.170436,	RCNNAcc=0.908681,	RCNNLogLoss=0.264939,	RCNNL1Loss=0.331877,	
INFO:root:Epoch[1] Batch [3320]	Speed: 1.59 samples/sec	Train-RPNAcc=0.872572,	RPNLogLoss=0.284940,	RPNL1Loss=0.170098,	RCNNAcc=0.908821,	RCNNLogLoss=0.264595,	RCNNL1Loss=0.331978,	
INFO:root:Epoch[1] Batch [3340]	Speed: 1.43 samples/sec	Train-RPNAcc=0.872867,	RPNLogLoss=0.284320,	RPNL1Loss=0.169857,	RCNNAcc=0.908925,	RCNNLogLoss=0.264130,	RCNNL1Loss=0.332179,	
INFO:root:Epoch[1] Batch [3360]	Speed: 1.04 samples/sec	Train-RPNAcc=0.873245,	RPNLogLoss=0.283598,	RPNL1Loss=0.169570,	RCNNAcc=0.909095,	RCNNLogLoss=0.263568,	RCNNL1Loss=0.332351,	
INFO:root:Epoch[1] Batch [3380]	Speed: 1.54 samples/sec	Train-RPNAcc=0.873528,	RPNLogLoss=0.282981,	RPNL1Loss=0.169131,	RCNNAcc=0.909226,	RCNNLogLoss=0.263034,	RCNNL1Loss=0.332256,	
INFO:root:Epoch[1] Batch [3400]	Speed: 1.68 samples/sec	Train-RPNAcc=0.873896,	RPNLogLoss=0.282298,	RPNL1Loss=0.168987,	RCNNAcc=0.909351,	RCNNLogLoss=0.262459,	RCNNL1Loss=0.332253,	
INFO:root:Epoch[1] Batch [3420]	Speed: 1.70 samples/sec	Train-RPNAcc=0.874177,	RPNLogLoss=0.281757,	RPNL1Loss=0.168623,	RCNNAcc=0.909504,	RCNNLogLoss=0.262052,	RCNNL1Loss=0.332107,	
INFO:root:Epoch[1] Batch [3440]	Speed: 1.44 samples/sec	Train-RPNAcc=0.874489,	RPNLogLoss=0.281142,	RPNL1Loss=0.168451,	RCNNAcc=0.909649,	RCNNLogLoss=0.261564,	RCNNL1Loss=0.332033,	
INFO:root:Epoch[1] Batch [3460]	Speed: 1.68 samples/sec	Train-RPNAcc=0.874767,	RPNLogLoss=0.280515,	RPNL1Loss=0.168075,	RCNNAcc=0.909780,	RCNNLogLoss=0.261057,	RCNNL1Loss=0.331870,	
INFO:root:Epoch[1] Batch [3480]	Speed: 1.39 samples/sec	Train-RPNAcc=0.875097,	RPNLogLoss=0.279856,	RPNL1Loss=0.167854,	RCNNAcc=0.909877,	RCNNLogLoss=0.260614,	RCNNL1Loss=0.331856,	
INFO:root:Epoch[1] Batch [3500]	Speed: 0.99 samples/sec	Train-RPNAcc=0.875370,	RPNLogLoss=0.279239,	RPNL1Loss=0.167639,	RCNNAcc=0.910061,	RCNNLogLoss=0.260055,	RCNNL1Loss=0.331495,	
INFO:root:Epoch[1] Batch [3520]	Speed: 1.65 samples/sec	Train-RPNAcc=0.875750,	RPNLogLoss=0.278525,	RPNL1Loss=0.167489,	RCNNAcc=0.910184,	RCNNLogLoss=0.259669,	RCNNL1Loss=0.331343,	
INFO:root:Epoch[1] Batch [3540]	Speed: 1.62 samples/sec	Train-RPNAcc=0.876017,	RPNLogLoss=0.277938,	RPNL1Loss=0.167125,	RCNNAcc=0.910217,	RCNNLogLoss=0.259496,	RCNNL1Loss=0.331346,	
INFO:root:Epoch[1] Batch [3560]	Speed: 1.26 samples/sec	Train-RPNAcc=0.876345,	RPNLogLoss=0.277285,	RPNL1Loss=0.166653,	RCNNAcc=0.910346,	RCNNLogLoss=0.259038,	RCNNL1Loss=0.331220,	
INFO:root:Epoch[1] Batch [3580]	Speed: 1.14 samples/sec	Train-RPNAcc=0.876646,	RPNLogLoss=0.276671,	RPNL1Loss=0.166419,	RCNNAcc=0.910456,	RCNNLogLoss=0.258577,	RCNNL1Loss=0.331315,	
INFO:root:Epoch[1] Batch [3600]	Speed: 1.77 samples/sec	Train-RPNAcc=0.876898,	RPNLogLoss=0.276200,	RPNL1Loss=0.166348,	RCNNAcc=0.910567,	RCNNLogLoss=0.258157,	RCNNL1Loss=0.331267,	
INFO:root:Epoch[1] Batch [3620]	Speed: 1.62 samples/sec	Train-RPNAcc=0.877148,	RPNLogLoss=0.275629,	RPNL1Loss=0.166093,	RCNNAcc=0.910688,	RCNNLogLoss=0.257813,	RCNNL1Loss=0.331400,	
INFO:root:Epoch[1] Batch [3640]	Speed: 1.52 samples/sec	Train-RPNAcc=0.877420,	RPNLogLoss=0.275150,	RPNL1Loss=0.165911,	RCNNAcc=0.910801,	RCNNLogLoss=0.257289,	RCNNL1Loss=0.331408,	
INFO:root:Epoch[1] Batch [3660]	Speed: 1.73 samples/sec	Train-RPNAcc=0.877728,	RPNLogLoss=0.274542,	RPNL1Loss=0.165559,	RCNNAcc=0.910962,	RCNNLogLoss=0.256772,	RCNNL1Loss=0.331221,	
INFO:root:Epoch[1] Batch [3680]	Speed: 1.70 samples/sec	Train-RPNAcc=0.877956,	RPNLogLoss=0.273997,	RPNL1Loss=0.165143,	RCNNAcc=0.911059,	RCNNLogLoss=0.256462,	RCNNL1Loss=0.331116,	
INFO:root:Epoch[1] Batch [3700]	Speed: 1.67 samples/sec	Train-RPNAcc=0.878292,	RPNLogLoss=0.273322,	RPNL1Loss=0.164787,	RCNNAcc=0.911215,	RCNNLogLoss=0.255964,	RCNNL1Loss=0.330878,	
INFO:root:Epoch[1] Batch [3720]	Speed: 1.72 samples/sec	Train-RPNAcc=0.878577,	RPNLogLoss=0.272725,	RPNL1Loss=0.164407,	RCNNAcc=0.911331,	RCNNLogLoss=0.255501,	RCNNL1Loss=0.330784,	
INFO:root:Epoch[1] Batch [3740]	Speed: 1.72 samples/sec	Train-RPNAcc=0.878738,	RPNLogLoss=0.272300,	RPNL1Loss=0.164022,	RCNNAcc=0.911421,	RCNNLogLoss=0.255120,	RCNNL1Loss=0.330827,	
INFO:root:Epoch[1] Batch [3760]	Speed: 1.79 samples/sec	Train-RPNAcc=0.879082,	RPNLogLoss=0.271581,	RPNL1Loss=0.163601,	RCNNAcc=0.911576,	RCNNLogLoss=0.254639,	RCNNL1Loss=0.330600,	
INFO:root:Epoch[1] Batch [3780]	Speed: 1.46 samples/sec	Train-RPNAcc=0.879343,	RPNLogLoss=0.271039,	RPNL1Loss=0.163438,	RCNNAcc=0.911639,	RCNNLogLoss=0.254352,	RCNNL1Loss=0.330663,	
INFO:root:Epoch[1] Batch [3800]	Speed: 1.56 samples/sec	Train-RPNAcc=0.879593,	RPNLogLoss=0.270544,	RPNL1Loss=0.163104,	RCNNAcc=0.911754,	RCNNLogLoss=0.253967,	RCNNL1Loss=0.330615,	
INFO:root:Epoch[1] Batch [3820]	Speed: 0.91 samples/sec	Train-RPNAcc=0.879912,	RPNLogLoss=0.269917,	RPNL1Loss=0.162712,	RCNNAcc=0.911989,	RCNNLogLoss=0.253310,	RCNNL1Loss=0.330188,	
INFO:root:Epoch[1] Batch [3840]	Speed: 1.69 samples/sec	Train-RPNAcc=0.880153,	RPNLogLoss=0.269430,	RPNL1Loss=0.162457,	RCNNAcc=0.912049,	RCNNLogLoss=0.252985,	RCNNL1Loss=0.330167,	
INFO:root:Epoch[1] Batch [3860]	Speed: 1.68 samples/sec	Train-RPNAcc=0.880384,	RPNLogLoss=0.268904,	RPNL1Loss=0.162089,	RCNNAcc=0.912203,	RCNNLogLoss=0.252488,	RCNNL1Loss=0.330057,	
INFO:root:Epoch[1] Batch [3880]	Speed: 1.65 samples/sec	Train-RPNAcc=0.880622,	RPNLogLoss=0.268409,	RPNL1Loss=0.161889,	RCNNAcc=0.912319,	RCNNLogLoss=0.252135,	RCNNL1Loss=0.329745,	
INFO:root:Epoch[1] Batch [3900]	Speed: 1.66 samples/sec	Train-RPNAcc=0.880907,	RPNLogLoss=0.267867,	RPNL1Loss=0.161717,	RCNNAcc=0.912422,	RCNNLogLoss=0.251797,	RCNNL1Loss=0.329709,	
INFO:root:Epoch[1] Batch [3920]	Speed: 1.68 samples/sec	Train-RPNAcc=0.881134,	RPNLogLoss=0.267412,	RPNL1Loss=0.161472,	RCNNAcc=0.912528,	RCNNLogLoss=0.251493,	RCNNL1Loss=0.329681,	
INFO:root:Epoch[1] Batch [3940]	Speed: 1.64 samples/sec	Train-RPNAcc=0.881283,	RPNLogLoss=0.267048,	RPNL1Loss=0.161422,	RCNNAcc=0.912564,	RCNNLogLoss=0.251260,	RCNNL1Loss=0.329514,	
INFO:root:Epoch[1] Batch [3960]	Speed: 1.65 samples/sec	Train-RPNAcc=0.881539,	RPNLogLoss=0.266511,	RPNL1Loss=0.161336,	RCNNAcc=0.912603,	RCNNLogLoss=0.251084,	RCNNL1Loss=0.329470,	
INFO:root:Epoch[1] Batch [3980]	Speed: 1.40 samples/sec	Train-RPNAcc=0.881776,	RPNLogLoss=0.266015,	RPNL1Loss=0.160966,	RCNNAcc=0.912701,	RCNNLogLoss=0.250829,	RCNNL1Loss=0.329372,	
INFO:root:Epoch[1] Batch [4000]	Speed: 1.04 samples/sec	Train-RPNAcc=0.882073,	RPNLogLoss=0.265427,	RPNL1Loss=0.160591,	RCNNAcc=0.912836,	RCNNLogLoss=0.250363,	RCNNL1Loss=0.329231,	
INFO:root:Epoch[1] Batch [4020]	Speed: 1.22 samples/sec	Train-RPNAcc=0.882302,	RPNLogLoss=0.264996,	RPNL1Loss=0.160352,	RCNNAcc=0.912943,	RCNNLogLoss=0.250145,	RCNNL1Loss=0.329243,	
INFO:root:Epoch[1] Batch [4040]	Speed: 1.62 samples/sec	Train-RPNAcc=0.882329,	RPNLogLoss=0.264766,	RPNL1Loss=0.160258,	RCNNAcc=0.912990,	RCNNLogLoss=0.250005,	RCNNL1Loss=0.329178,	
INFO:root:Epoch[1] Batch [4060]	Speed: 1.52 samples/sec	Train-RPNAcc=0.882615,	RPNLogLoss=0.264188,	RPNL1Loss=0.159988,	RCNNAcc=0.913133,	RCNNLogLoss=0.249549,	RCNNL1Loss=0.328938,	
INFO:root:Epoch[1] Batch [4080]	Speed: 1.56 samples/sec	Train-RPNAcc=0.882822,	RPNLogLoss=0.263788,	RPNL1Loss=0.159820,	RCNNAcc=0.913159,	RCNNLogLoss=0.249315,	RCNNL1Loss=0.329001,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [4100]	Speed: 1.63 samples/sec	Train-RPNAcc=0.883068,	RPNLogLoss=0.263251,	RPNL1Loss=0.159579,	RCNNAcc=0.913283,	RCNNLogLoss=0.248932,	RCNNL1Loss=0.328841,	
INFO:root:Epoch[1] Batch [4120]	Speed: 1.56 samples/sec	Train-RPNAcc=0.883255,	RPNLogLoss=0.262827,	RPNL1Loss=0.159279,	RCNNAcc=0.913372,	RCNNLogLoss=0.248731,	RCNNL1Loss=0.328809,	
INFO:root:Epoch[1] Batch [4140]	Speed: 0.95 samples/sec	Train-RPNAcc=0.883545,	RPNLogLoss=0.262274,	RPNL1Loss=0.158928,	RCNNAcc=0.913540,	RCNNLogLoss=0.248230,	RCNNL1Loss=0.328722,	
INFO:root:Epoch[1] Batch [4160]	Speed: 1.63 samples/sec	Train-RPNAcc=0.883709,	RPNLogLoss=0.261882,	RPNL1Loss=0.158852,	RCNNAcc=0.913644,	RCNNLogLoss=0.247827,	RCNNL1Loss=0.328655,	
INFO:root:Epoch[1] Batch [4180]	Speed: 1.76 samples/sec	Train-RPNAcc=0.883957,	RPNLogLoss=0.261371,	RPNL1Loss=0.158507,	RCNNAcc=0.913793,	RCNNLogLoss=0.247366,	RCNNL1Loss=0.328569,	
INFO:root:Epoch[1] Batch [4200]	Speed: 1.57 samples/sec	Train-RPNAcc=0.884167,	RPNLogLoss=0.260930,	RPNL1Loss=0.158195,	RCNNAcc=0.913821,	RCNNLogLoss=0.247328,	RCNNL1Loss=0.328696,	
INFO:root:Epoch[1] Batch [4220]	Speed: 1.78 samples/sec	Train-RPNAcc=0.884309,	RPNLogLoss=0.260555,	RPNL1Loss=0.157940,	RCNNAcc=0.913909,	RCNNLogLoss=0.246996,	RCNNL1Loss=0.328687,	
INFO:root:Epoch[1] Batch [4240]	Speed: 1.68 samples/sec	Train-RPNAcc=0.884493,	RPNLogLoss=0.260230,	RPNL1Loss=0.157770,	RCNNAcc=0.914013,	RCNNLogLoss=0.246625,	RCNNL1Loss=0.328583,	
INFO:root:Epoch[1] Batch [4260]	Speed: 1.78 samples/sec	Train-RPNAcc=0.884728,	RPNLogLoss=0.259746,	RPNL1Loss=0.157590,	RCNNAcc=0.914097,	RCNNLogLoss=0.246372,	RCNNL1Loss=0.328531,	
INFO:root:Epoch[1] Batch [4280]	Speed: 1.70 samples/sec	Train-RPNAcc=0.884949,	RPNLogLoss=0.259284,	RPNL1Loss=0.157288,	RCNNAcc=0.914245,	RCNNLogLoss=0.245934,	RCNNL1Loss=0.328216,	
INFO:root:Epoch[1] Batch [4300]	Speed: 1.82 samples/sec	Train-RPNAcc=0.885168,	RPNLogLoss=0.258809,	RPNL1Loss=0.156971,	RCNNAcc=0.914368,	RCNNLogLoss=0.245577,	RCNNL1Loss=0.328049,	
INFO:root:Epoch[1] Batch [4320]	Speed: 1.72 samples/sec	Train-RPNAcc=0.885327,	RPNLogLoss=0.258394,	RPNL1Loss=0.156709,	RCNNAcc=0.914451,	RCNNLogLoss=0.245265,	RCNNL1Loss=0.328040,	
INFO:root:Epoch[1] Batch [4340]	Speed: 1.78 samples/sec	Train-RPNAcc=0.885553,	RPNLogLoss=0.257919,	RPNL1Loss=0.156481,	RCNNAcc=0.914550,	RCNNLogLoss=0.244921,	RCNNL1Loss=0.327806,	
INFO:root:Epoch[1] Batch [4360]	Speed: 1.49 samples/sec	Train-RPNAcc=0.885831,	RPNLogLoss=0.257364,	RPNL1Loss=0.156262,	RCNNAcc=0.914738,	RCNNLogLoss=0.244378,	RCNNL1Loss=0.327378,	
INFO:root:Epoch[1] Batch [4380]	Speed: 1.75 samples/sec	Train-RPNAcc=0.886039,	RPNLogLoss=0.256917,	RPNL1Loss=0.155966,	RCNNAcc=0.914885,	RCNNLogLoss=0.243975,	RCNNL1Loss=0.327293,	
INFO:root:Epoch[1] Batch [4400]	Speed: 1.87 samples/sec	Train-RPNAcc=0.886334,	RPNLogLoss=0.256384,	RPNL1Loss=0.155646,	RCNNAcc=0.915010,	RCNNLogLoss=0.243671,	RCNNL1Loss=0.327141,	
INFO:root:Epoch[1] Batch [4420]	Speed: 1.77 samples/sec	Train-RPNAcc=0.886522,	RPNLogLoss=0.256024,	RPNL1Loss=0.155446,	RCNNAcc=0.915082,	RCNNLogLoss=0.243432,	RCNNL1Loss=0.327121,	
INFO:root:Epoch[1] Batch [4440]	Speed: 1.45 samples/sec	Train-RPNAcc=0.886758,	RPNLogLoss=0.255504,	RPNL1Loss=0.155214,	RCNNAcc=0.915206,	RCNNLogLoss=0.243052,	RCNNL1Loss=0.327123,	
INFO:root:Epoch[1] Batch [4460]	Speed: 1.31 samples/sec	Train-RPNAcc=0.887016,	RPNLogLoss=0.255065,	RPNL1Loss=0.155146,	RCNNAcc=0.915320,	RCNNLogLoss=0.242694,	RCNNL1Loss=0.327055,	
INFO:root:Epoch[1] Batch [4480]	Speed: 1.37 samples/sec	Train-RPNAcc=0.887133,	RPNLogLoss=0.254805,	RPNL1Loss=0.155136,	RCNNAcc=0.915360,	RCNNLogLoss=0.242551,	RCNNL1Loss=0.327056,	
INFO:root:Epoch[1] Batch [4500]	Speed: 1.71 samples/sec	Train-RPNAcc=0.887354,	RPNLogLoss=0.254392,	RPNL1Loss=0.154957,	RCNNAcc=0.915413,	RCNNLogLoss=0.242335,	RCNNL1Loss=0.326973,	
INFO:root:Epoch[1] Batch [4520]	Speed: 1.70 samples/sec	Train-RPNAcc=0.887609,	RPNLogLoss=0.253944,	RPNL1Loss=0.154819,	RCNNAcc=0.915504,	RCNNLogLoss=0.242026,	RCNNL1Loss=0.326882,	
INFO:root:Epoch[1] Batch [4540]	Speed: 1.52 samples/sec	Train-RPNAcc=0.887736,	RPNLogLoss=0.253656,	RPNL1Loss=0.154865,	RCNNAcc=0.915499,	RCNNLogLoss=0.241910,	RCNNL1Loss=0.327079,	
INFO:root:Epoch[1] Batch [4560]	Speed: 1.69 samples/sec	Train-RPNAcc=0.887991,	RPNLogLoss=0.253156,	RPNL1Loss=0.154636,	RCNNAcc=0.915561,	RCNNLogLoss=0.241587,	RCNNL1Loss=0.327091,	
INFO:root:Epoch[1] Batch [4580]	Speed: 1.62 samples/sec	Train-RPNAcc=0.888267,	RPNLogLoss=0.252630,	RPNL1Loss=0.154433,	RCNNAcc=0.915666,	RCNNLogLoss=0.241254,	RCNNL1Loss=0.327117,	
INFO:root:Epoch[1] Batch [4600]	Speed: 1.44 samples/sec	Train-RPNAcc=0.888444,	RPNLogLoss=0.252233,	RPNL1Loss=0.154162,	RCNNAcc=0.915834,	RCNNLogLoss=0.240813,	RCNNL1Loss=0.326745,	
INFO:root:Epoch[1] Batch [4620]	Speed: 1.63 samples/sec	Train-RPNAcc=0.888589,	RPNLogLoss=0.251951,	RPNL1Loss=0.154071,	RCNNAcc=0.915856,	RCNNLogLoss=0.240703,	RCNNL1Loss=0.326959,	
INFO:root:Epoch[1] Batch [4640]	Speed: 1.90 samples/sec	Train-RPNAcc=0.888817,	RPNLogLoss=0.251518,	RPNL1Loss=0.153706,	RCNNAcc=0.915904,	RCNNLogLoss=0.240418,	RCNNL1Loss=0.326907,	
INFO:root:Epoch[1] Batch [4660]	Speed: 1.91 samples/sec	Train-RPNAcc=0.889080,	RPNLogLoss=0.251035,	RPNL1Loss=0.153467,	RCNNAcc=0.916054,	RCNNLogLoss=0.239974,	RCNNL1Loss=0.326644,	
INFO:root:Epoch[1] Batch [4680]	Speed: 1.81 samples/sec	Train-RPNAcc=0.889261,	RPNLogLoss=0.250670,	RPNL1Loss=0.153228,	RCNNAcc=0.916130,	RCNNLogLoss=0.239810,	RCNNL1Loss=0.326788,	
INFO:root:Epoch[1] Batch [4700]	Speed: 1.73 samples/sec	Train-RPNAcc=0.889409,	RPNLogLoss=0.250392,	RPNL1Loss=0.153143,	RCNNAcc=0.916193,	RCNNLogLoss=0.239757,	RCNNL1Loss=0.326745,	
INFO:root:Epoch[1] Batch [4720]	Speed: 1.83 samples/sec	Train-RPNAcc=0.889635,	RPNLogLoss=0.249914,	RPNL1Loss=0.152944,	RCNNAcc=0.916267,	RCNNLogLoss=0.239486,	RCNNL1Loss=0.326714,	
INFO:root:Epoch[1] Batch [4740]	Speed: 1.73 samples/sec	Train-RPNAcc=0.889786,	RPNLogLoss=0.249607,	RPNL1Loss=0.152925,	RCNNAcc=0.916304,	RCNNLogLoss=0.239393,	RCNNL1Loss=0.326782,	
INFO:root:Epoch[1] Batch [4760]	Speed: 1.82 samples/sec	Train-RPNAcc=0.890002,	RPNLogLoss=0.249214,	RPNL1Loss=0.152736,	RCNNAcc=0.916407,	RCNNLogLoss=0.239069,	RCNNL1Loss=0.326698,	
INFO:root:Epoch[1] Batch [4780]	Speed: 1.73 samples/sec	Train-RPNAcc=0.890113,	RPNLogLoss=0.248956,	RPNL1Loss=0.152706,	RCNNAcc=0.916425,	RCNNLogLoss=0.238878,	RCNNL1Loss=0.326569,	
INFO:root:Epoch[1] Batch [4800]	Speed: 1.93 samples/sec	Train-RPNAcc=0.890282,	RPNLogLoss=0.248646,	RPNL1Loss=0.152403,	RCNNAcc=0.916487,	RCNNLogLoss=0.238619,	RCNNL1Loss=0.326569,	
INFO:root:Epoch[1] Batch [4820]	Speed: 1.75 samples/sec	Train-RPNAcc=0.890503,	RPNLogLoss=0.248289,	RPNL1Loss=0.152259,	RCNNAcc=0.916545,	RCNNLogLoss=0.238371,	RCNNL1Loss=0.326406,	
INFO:root:Epoch[1] Batch [4840]	Speed: 1.79 samples/sec	Train-RPNAcc=0.890681,	RPNLogLoss=0.247919,	RPNL1Loss=0.152039,	RCNNAcc=0.916638,	RCNNLogLoss=0.238059,	RCNNL1Loss=0.326271,	
INFO:root:Epoch[1] Batch [4860]	Speed: 1.76 samples/sec	Train-RPNAcc=0.890861,	RPNLogLoss=0.247558,	RPNL1Loss=0.151959,	RCNNAcc=0.916695,	RCNNLogLoss=0.237764,	RCNNL1Loss=0.326266,	
INFO:root:Epoch[1] Batch [4880]	Speed: 1.44 samples/sec	Train-RPNAcc=0.890983,	RPNLogLoss=0.247305,	RPNL1Loss=0.151928,	RCNNAcc=0.916760,	RCNNLogLoss=0.237627,	RCNNL1Loss=0.326348,	
INFO:root:Epoch[1] Batch [4900]	Speed: 1.45 samples/sec	Train-RPNAcc=0.891142,	RPNLogLoss=0.246980,	RPNL1Loss=0.151808,	RCNNAcc=0.916841,	RCNNLogLoss=0.237340,	RCNNL1Loss=0.326415,	
INFO:root:Epoch[1] Batch [4920]	Speed: 0.92 samples/sec	Train-RPNAcc=0.891304,	RPNLogLoss=0.246696,	RPNL1Loss=0.151628,	RCNNAcc=0.916869,	RCNNLogLoss=0.237267,	RCNNL1Loss=0.326382,	
INFO:root:Epoch[1] Batch [4940]	Speed: 1.84 samples/sec	Train-RPNAcc=0.891453,	RPNLogLoss=0.246350,	RPNL1Loss=0.151302,	RCNNAcc=0.916896,	RCNNLogLoss=0.237175,	RCNNL1Loss=0.326409,	
INFO:root:Epoch[1] Batch [4960]	Speed: 1.73 samples/sec	Train-RPNAcc=0.891624,	RPNLogLoss=0.246066,	RPNL1Loss=0.151142,	RCNNAcc=0.916952,	RCNNLogLoss=0.237000,	RCNNL1Loss=0.326427,	
INFO:root:Epoch[1] Batch [4980]	Speed: 1.60 samples/sec	Train-RPNAcc=0.891797,	RPNLogLoss=0.245693,	RPNL1Loss=0.150959,	RCNNAcc=0.917033,	RCNNLogLoss=0.236704,	RCNNL1Loss=0.326357,	
INFO:root:Epoch[1] Batch [5000]	Speed: 1.78 samples/sec	Train-RPNAcc=0.891929,	RPNLogLoss=0.245400,	RPNL1Loss=0.150811,	RCNNAcc=0.917090,	RCNNLogLoss=0.236490,	RCNNL1Loss=0.326442,	
INFO:root:Epoch[1] Batch [5020]	Speed: 1.85 samples/sec	Train-RPNAcc=0.892169,	RPNLogLoss=0.245017,	RPNL1Loss=0.150636,	RCNNAcc=0.917160,	RCNNLogLoss=0.236306,	RCNNL1Loss=0.326357,	
INFO:root:Epoch[1] Batch [5040]	Speed: 1.21 samples/sec	Train-RPNAcc=0.892300,	RPNLogLoss=0.244744,	RPNL1Loss=0.150513,	RCNNAcc=0.917157,	RCNNLogLoss=0.236262,	RCNNL1Loss=0.326501,	
INFO:root:Epoch[1] Batch [5060]	Speed: 1.82 samples/sec	Train-RPNAcc=0.892498,	RPNLogLoss=0.244387,	RPNL1Loss=0.150315,	RCNNAcc=0.917233,	RCNNLogLoss=0.236005,	RCNNL1Loss=0.326503,	
INFO:root:Epoch[1] Batch [5080]	Speed: 1.68 samples/sec	Train-RPNAcc=0.892742,	RPNLogLoss=0.243925,	RPNL1Loss=0.150080,	RCNNAcc=0.917328,	RCNNLogLoss=0.235714,	RCNNL1Loss=0.326487,	
INFO:root:Epoch[1] Batch [5100]	Speed: 1.81 samples/sec	Train-RPNAcc=0.892994,	RPNLogLoss=0.243452,	RPNL1Loss=0.149816,	RCNNAcc=0.917426,	RCNNLogLoss=0.235384,	RCNNL1Loss=0.326419,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [5120]	Speed: 1.70 samples/sec	Train-RPNAcc=0.893202,	RPNLogLoss=0.243098,	RPNL1Loss=0.149700,	RCNNAcc=0.917478,	RCNNLogLoss=0.235153,	RCNNL1Loss=0.326344,	
INFO:root:Epoch[1] Batch [5140]	Speed: 1.81 samples/sec	Train-RPNAcc=0.893385,	RPNLogLoss=0.242699,	RPNL1Loss=0.149516,	RCNNAcc=0.917599,	RCNNLogLoss=0.234788,	RCNNL1Loss=0.326334,	
INFO:root:Epoch[1] Batch [5160]	Speed: 1.74 samples/sec	Train-RPNAcc=0.893580,	RPNLogLoss=0.242312,	RPNL1Loss=0.149327,	RCNNAcc=0.917680,	RCNNLogLoss=0.234552,	RCNNL1Loss=0.326221,	
INFO:root:Epoch[1] Batch [5180]	Speed: 1.93 samples/sec	Train-RPNAcc=0.893817,	RPNLogLoss=0.241837,	RPNL1Loss=0.149052,	RCNNAcc=0.917792,	RCNNLogLoss=0.234189,	RCNNL1Loss=0.326180,	
INFO:root:Epoch[1] Batch [5200]	Speed: 1.75 samples/sec	Train-RPNAcc=0.894045,	RPNLogLoss=0.241414,	RPNL1Loss=0.148913,	RCNNAcc=0.917888,	RCNNLogLoss=0.233888,	RCNNL1Loss=0.325897,	
INFO:root:Epoch[1] Batch [5220]	Speed: 1.86 samples/sec	Train-RPNAcc=0.894266,	RPNLogLoss=0.241010,	RPNL1Loss=0.148681,	RCNNAcc=0.917971,	RCNNLogLoss=0.233586,	RCNNL1Loss=0.325846,	
INFO:root:Epoch[1] Batch [5240]	Speed: 1.98 samples/sec	Train-RPNAcc=0.894491,	RPNLogLoss=0.240575,	RPNL1Loss=0.148409,	RCNNAcc=0.918062,	RCNNLogLoss=0.233255,	RCNNL1Loss=0.325744,	
INFO:root:Epoch[1] Batch [5260]	Speed: 1.82 samples/sec	Train-RPNAcc=0.894598,	RPNLogLoss=0.240348,	RPNL1Loss=0.148273,	RCNNAcc=0.918097,	RCNNLogLoss=0.233141,	RCNNL1Loss=0.325626,	
INFO:root:Epoch[1] Batch [5280]	Speed: 1.83 samples/sec	Train-RPNAcc=0.894800,	RPNLogLoss=0.239971,	RPNL1Loss=0.148056,	RCNNAcc=0.918146,	RCNNLogLoss=0.233029,	RCNNL1Loss=0.325583,	
INFO:root:Epoch[1] Batch [5300]	Speed: 1.83 samples/sec	Train-RPNAcc=0.895021,	RPNLogLoss=0.239508,	RPNL1Loss=0.147760,	RCNNAcc=0.918245,	RCNNLogLoss=0.232708,	RCNNL1Loss=0.325515,	
INFO:root:Epoch[1] Batch [5320]	Speed: 1.83 samples/sec	Train-RPNAcc=0.895204,	RPNLogLoss=0.239161,	RPNL1Loss=0.147645,	RCNNAcc=0.918325,	RCNNLogLoss=0.232423,	RCNNL1Loss=0.325401,	
INFO:root:Epoch[1] Batch [5340]	Speed: 1.78 samples/sec	Train-RPNAcc=0.895396,	RPNLogLoss=0.238797,	RPNL1Loss=0.147472,	RCNNAcc=0.918420,	RCNNLogLoss=0.232178,	RCNNL1Loss=0.325296,	
INFO:root:Epoch[1] Batch [5360]	Speed: 1.66 samples/sec	Train-RPNAcc=0.895592,	RPNLogLoss=0.238420,	RPNL1Loss=0.147327,	RCNNAcc=0.918507,	RCNNLogLoss=0.231938,	RCNNL1Loss=0.325201,	
INFO:root:Epoch[1] Batch [5380]	Speed: 1.83 samples/sec	Train-RPNAcc=0.895790,	RPNLogLoss=0.238045,	RPNL1Loss=0.147179,	RCNNAcc=0.918663,	RCNNLogLoss=0.231522,	RCNNL1Loss=0.325093,	
INFO:root:Epoch[1] Batch [5400]	Speed: 1.66 samples/sec	Train-RPNAcc=0.895955,	RPNLogLoss=0.237708,	RPNL1Loss=0.146945,	RCNNAcc=0.918691,	RCNNLogLoss=0.231411,	RCNNL1Loss=0.325111,	
INFO:root:Epoch[1] Batch [5420]	Speed: 1.70 samples/sec	Train-RPNAcc=0.896073,	RPNLogLoss=0.237489,	RPNL1Loss=0.146899,	RCNNAcc=0.918752,	RCNNLogLoss=0.231187,	RCNNL1Loss=0.325058,	
INFO:root:Epoch[1] Batch [5440]	Speed: 1.75 samples/sec	Train-RPNAcc=0.896178,	RPNLogLoss=0.237305,	RPNL1Loss=0.146872,	RCNNAcc=0.918788,	RCNNLogLoss=0.231062,	RCNNL1Loss=0.325109,	
INFO:root:Epoch[1] Batch [5460]	Speed: 1.67 samples/sec	Train-RPNAcc=0.896353,	RPNLogLoss=0.236951,	RPNL1Loss=0.146729,	RCNNAcc=0.918876,	RCNNLogLoss=0.230729,	RCNNL1Loss=0.325000,	
INFO:root:Epoch[1] Batch [5480]	Speed: 1.78 samples/sec	Train-RPNAcc=0.896536,	RPNLogLoss=0.236600,	RPNL1Loss=0.146577,	RCNNAcc=0.918933,	RCNNLogLoss=0.230502,	RCNNL1Loss=0.325007,	
INFO:root:Epoch[1] Batch [5500]	Speed: 1.78 samples/sec	Train-RPNAcc=0.896591,	RPNLogLoss=0.236424,	RPNL1Loss=0.146554,	RCNNAcc=0.918961,	RCNNLogLoss=0.230336,	RCNNL1Loss=0.325116,	
INFO:root:Epoch[1] Batch [5520]	Speed: 1.42 samples/sec	Train-RPNAcc=0.896754,	RPNLogLoss=0.236108,	RPNL1Loss=0.146466,	RCNNAcc=0.918961,	RCNNLogLoss=0.230243,	RCNNL1Loss=0.325236,	
INFO:root:Epoch[1] Batch [5540]	Speed: 1.80 samples/sec	Train-RPNAcc=0.896889,	RPNLogLoss=0.235824,	RPNL1Loss=0.146269,	RCNNAcc=0.919020,	RCNNLogLoss=0.230065,	RCNNL1Loss=0.325302,	
INFO:root:Epoch[1] Batch [5560]	Speed: 1.34 samples/sec	Train-RPNAcc=0.897066,	RPNLogLoss=0.235472,	RPNL1Loss=0.146137,	RCNNAcc=0.919079,	RCNNLogLoss=0.229817,	RCNNL1Loss=0.325345,	
INFO:root:Epoch[1] Batch [5580]	Speed: 1.84 samples/sec	Train-RPNAcc=0.897195,	RPNLogLoss=0.235208,	RPNL1Loss=0.146055,	RCNNAcc=0.919134,	RCNNLogLoss=0.229604,	RCNNL1Loss=0.325255,	
INFO:root:Epoch[1] Batch [5600]	Speed: 1.46 samples/sec	Train-RPNAcc=0.897328,	RPNLogLoss=0.234949,	RPNL1Loss=0.145951,	RCNNAcc=0.919216,	RCNNLogLoss=0.229412,	RCNNL1Loss=0.325215,	
INFO:root:Epoch[1] Batch [5620]	Speed: 1.79 samples/sec	Train-RPNAcc=0.897476,	RPNLogLoss=0.234651,	RPNL1Loss=0.145854,	RCNNAcc=0.919243,	RCNNLogLoss=0.229311,	RCNNL1Loss=0.325128,	
INFO:root:Epoch[1] Batch [5640]	Speed: 1.85 samples/sec	Train-RPNAcc=0.897682,	RPNLogLoss=0.234273,	RPNL1Loss=0.145683,	RCNNAcc=0.919329,	RCNNLogLoss=0.229024,	RCNNL1Loss=0.325012,	
INFO:root:Epoch[1] Batch [5660]	Speed: 1.43 samples/sec	Train-RPNAcc=0.897868,	RPNLogLoss=0.233928,	RPNL1Loss=0.145571,	RCNNAcc=0.919427,	RCNNLogLoss=0.228737,	RCNNL1Loss=0.324859,	
INFO:root:Epoch[1] Batch [5680]	Speed: 1.83 samples/sec	Train-RPNAcc=0.898037,	RPNLogLoss=0.233618,	RPNL1Loss=0.145438,	RCNNAcc=0.919486,	RCNNLogLoss=0.228487,	RCNNL1Loss=0.324767,	
INFO:root:Epoch[1] Batch [5700]	Speed: 1.91 samples/sec	Train-RPNAcc=0.898251,	RPNLogLoss=0.233214,	RPNL1Loss=0.145238,	RCNNAcc=0.919603,	RCNNLogLoss=0.228173,	RCNNL1Loss=0.324587,	
INFO:root:Epoch[1] Batch [5720]	Speed: 1.59 samples/sec	Train-RPNAcc=0.898430,	RPNLogLoss=0.232845,	RPNL1Loss=0.145036,	RCNNAcc=0.919661,	RCNNLogLoss=0.228040,	RCNNL1Loss=0.324435,	
INFO:root:Epoch[1] Batch [5740]	Speed: 1.72 samples/sec	Train-RPNAcc=0.898574,	RPNLogLoss=0.232557,	RPNL1Loss=0.144871,	RCNNAcc=0.919707,	RCNNLogLoss=0.227812,	RCNNL1Loss=0.324482,	
INFO:root:Epoch[1] Batch [5760]	Speed: 1.84 samples/sec	Train-RPNAcc=0.898734,	RPNLogLoss=0.232230,	RPNL1Loss=0.144705,	RCNNAcc=0.919795,	RCNNLogLoss=0.227578,	RCNNL1Loss=0.324473,	
INFO:root:Epoch[1] Batch [5780]	Speed: 1.86 samples/sec	Train-RPNAcc=0.898889,	RPNLogLoss=0.231897,	RPNL1Loss=0.144571,	RCNNAcc=0.919918,	RCNNLogLoss=0.227233,	RCNNL1Loss=0.324400,	
INFO:root:Epoch[1] Batch [5800]	Speed: 1.91 samples/sec	Train-RPNAcc=0.899085,	RPNLogLoss=0.231501,	RPNL1Loss=0.144422,	RCNNAcc=0.920011,	RCNNLogLoss=0.226947,	RCNNL1Loss=0.324237,	
INFO:root:Epoch[1] Batch [5820]	Speed: 1.81 samples/sec	Train-RPNAcc=0.899241,	RPNLogLoss=0.231174,	RPNL1Loss=0.144167,	RCNNAcc=0.920098,	RCNNLogLoss=0.226758,	RCNNL1Loss=0.324045,	
INFO:root:Epoch[1] Batch [5840]	Speed: 1.65 samples/sec	Train-RPNAcc=0.899411,	RPNLogLoss=0.230834,	RPNL1Loss=0.144136,	RCNNAcc=0.920184,	RCNNLogLoss=0.226477,	RCNNL1Loss=0.323932,	
INFO:root:Epoch[1] Batch [5860]	Speed: 1.62 samples/sec	Train-RPNAcc=0.899569,	RPNLogLoss=0.230463,	RPNL1Loss=0.144021,	RCNNAcc=0.920289,	RCNNLogLoss=0.226152,	RCNNL1Loss=0.323913,	
INFO:root:Epoch[1] Batch [5880]	Speed: 1.62 samples/sec	Train-RPNAcc=0.899718,	RPNLogLoss=0.230171,	RPNL1Loss=0.143972,	RCNNAcc=0.920342,	RCNNLogLoss=0.226013,	RCNNL1Loss=0.323827,	
INFO:root:Epoch[1] Batch [5900]	Speed: 1.84 samples/sec	Train-RPNAcc=0.899904,	RPNLogLoss=0.229808,	RPNL1Loss=0.143724,	RCNNAcc=0.920421,	RCNNLogLoss=0.225736,	RCNNL1Loss=0.323712,	
INFO:root:Epoch[1] Batch [5920]	Speed: 1.74 samples/sec	Train-RPNAcc=0.900081,	RPNLogLoss=0.229472,	RPNL1Loss=0.143613,	RCNNAcc=0.920509,	RCNNLogLoss=0.225489,	RCNNL1Loss=0.323787,	
INFO:root:Epoch[1] Batch [5940]	Speed: 1.64 samples/sec	Train-RPNAcc=0.900192,	RPNLogLoss=0.229258,	RPNL1Loss=0.143505,	RCNNAcc=0.920534,	RCNNLogLoss=0.225375,	RCNNL1Loss=0.323791,	
INFO:root:Epoch[1] Batch [5960]	Speed: 1.83 samples/sec	Train-RPNAcc=0.900396,	RPNLogLoss=0.228879,	RPNL1Loss=0.143419,	RCNNAcc=0.920617,	RCNNLogLoss=0.225119,	RCNNL1Loss=0.323686,	
INFO:root:Epoch[1] Batch [5980]	Speed: 1.87 samples/sec	Train-RPNAcc=0.900591,	RPNLogLoss=0.228504,	RPNL1Loss=0.143271,	RCNNAcc=0.920673,	RCNNLogLoss=0.224945,	RCNNL1Loss=0.323546,	
INFO:root:Epoch[1] Batch [6000]	Speed: 1.36 samples/sec	Train-RPNAcc=0.900740,	RPNLogLoss=0.228212,	RPNL1Loss=0.143114,	RCNNAcc=0.920714,	RCNNLogLoss=0.224751,	RCNNL1Loss=0.323571,	
INFO:root:Epoch[1] Batch [6020]	Speed: 1.57 samples/sec	Train-RPNAcc=0.900882,	RPNLogLoss=0.227957,	RPNL1Loss=0.142936,	RCNNAcc=0.920723,	RCNNLogLoss=0.224676,	RCNNL1Loss=0.323640,	
INFO:root:Epoch[1] Batch [6040]	Speed: 1.82 samples/sec	Train-RPNAcc=0.901019,	RPNLogLoss=0.227659,	RPNL1Loss=0.142769,	RCNNAcc=0.920774,	RCNNLogLoss=0.224458,	RCNNL1Loss=0.323686,	
INFO:root:Epoch[1] Batch [6060]	Speed: 1.64 samples/sec	Train-RPNAcc=0.901093,	RPNLogLoss=0.227505,	RPNL1Loss=0.142663,	RCNNAcc=0.920764,	RCNNLogLoss=0.224398,	RCNNL1Loss=0.323783,	
INFO:root:Epoch[1] Batch [6080]	Speed: 1.82 samples/sec	Train-RPNAcc=0.901214,	RPNLogLoss=0.227278,	RPNL1Loss=0.142531,	RCNNAcc=0.920823,	RCNNLogLoss=0.224234,	RCNNL1Loss=0.323780,	
INFO:root:Epoch[1] Batch [6100]	Speed: 1.77 samples/sec	Train-RPNAcc=0.901346,	RPNLogLoss=0.227006,	RPNL1Loss=0.142375,	RCNNAcc=0.920842,	RCNNLogLoss=0.224093,	RCNNL1Loss=0.323809,	
INFO:root:Epoch[1] Batch [6120]	Speed: 1.66 samples/sec	Train-RPNAcc=0.901489,	RPNLogLoss=0.226742,	RPNL1Loss=0.142250,	RCNNAcc=0.920909,	RCNNLogLoss=0.223872,	RCNNL1Loss=0.323736,	
INFO:root:Epoch[1] Batch [6140]	Speed: 1.52 samples/sec	Train-RPNAcc=0.901615,	RPNLogLoss=0.226545,	RPNL1Loss=0.142253,	RCNNAcc=0.920962,	RCNNLogLoss=0.223810,	RCNNL1Loss=0.323740,	
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
INFO:root:Epoch[1] Batch [6160]	Speed: 1.55 samples/sec	Train-RPNAcc=0.901797,	RPNLogLoss=0.226204,	RPNL1Loss=0.142110,	RCNNAcc=0.921020,	RCNNLogLoss=0.223597,	RCNNL1Loss=0.323738,	
INFO:root:Epoch[1] Batch [6180]	Speed: 1.70 samples/sec	Train-RPNAcc=0.901934,	RPNLogLoss=0.225951,	RPNL1Loss=0.141975,	RCNNAcc=0.921060,	RCNNLogLoss=0.223421,	RCNNL1Loss=0.323666,	
INFO:root:Epoch[1] Batch [6200]	Speed: 1.86 samples/sec	Train-RPNAcc=0.902059,	RPNLogLoss=0.225711,	RPNL1Loss=0.141813,	RCNNAcc=0.921132,	RCNNLogLoss=0.223236,	RCNNL1Loss=0.323672,	
INFO:root:Epoch[1] Batch [6220]	Speed: 1.82 samples/sec	Train-RPNAcc=0.902245,	RPNLogLoss=0.225360,	RPNL1Loss=0.141670,	RCNNAcc=0.921218,	RCNNLogLoss=0.223028,	RCNNL1Loss=0.323703,	
INFO:root:Epoch[1] Batch [6240]	Speed: 1.83 samples/sec	Train-RPNAcc=0.902407,	RPNLogLoss=0.225031,	RPNL1Loss=0.141576,	RCNNAcc=0.921315,	RCNNLogLoss=0.222737,	RCNNL1Loss=0.323593,	
INFO:root:Epoch[1] Batch [6260]	Speed: 1.80 samples/sec	Train-RPNAcc=0.902560,	RPNLogLoss=0.224715,	RPNL1Loss=0.141360,	RCNNAcc=0.921388,	RCNNLogLoss=0.222464,	RCNNL1Loss=0.323354,	
INFO:root:Epoch[1] Batch [6280]	Speed: 1.70 samples/sec	Train-RPNAcc=0.902678,	RPNLogLoss=0.224474,	RPNL1Loss=0.141224,	RCNNAcc=0.921379,	RCNNLogLoss=0.222434,	RCNNL1Loss=0.323386,	
INFO:root:Epoch[1] Batch [6300]	Speed: 1.46 samples/sec	Train-RPNAcc=0.902806,	RPNLogLoss=0.224187,	RPNL1Loss=0.141135,	RCNNAcc=0.921440,	RCNNLogLoss=0.222272,	RCNNL1Loss=0.323439,	
INFO:root:Epoch[1] Batch [6320]	Speed: 1.80 samples/sec	Train-RPNAcc=0.902886,	RPNLogLoss=0.224007,	RPNL1Loss=0.141107,	RCNNAcc=0.921456,	RCNNLogLoss=0.222134,	RCNNL1Loss=0.323474,	
INFO:root:Epoch[1] Batch [6340]	Speed: 1.69 samples/sec	Train-RPNAcc=0.903042,	RPNLogLoss=0.223721,	RPNL1Loss=0.140948,	RCNNAcc=0.921480,	RCNNLogLoss=0.222020,	RCNNL1Loss=0.323488,	
INFO:root:Epoch[1] Batch [6360]	Speed: 1.74 samples/sec	Train-RPNAcc=0.903188,	RPNLogLoss=0.223475,	RPNL1Loss=0.140871,	RCNNAcc=0.921486,	RCNNLogLoss=0.221955,	RCNNL1Loss=0.323583,	
INFO:root:Epoch[1] Batch [6380]	Speed: 1.80 samples/sec	Train-RPNAcc=0.903306,	RPNLogLoss=0.223266,	RPNL1Loss=0.140866,	RCNNAcc=0.921508,	RCNNLogLoss=0.221897,	RCNNL1Loss=0.323680,	
INFO:root:Epoch[1] Batch [6400]	Speed: 1.79 samples/sec	Train-RPNAcc=0.903428,	RPNLogLoss=0.223071,	RPNL1Loss=0.140805,	RCNNAcc=0.921511,	RCNNLogLoss=0.221821,	RCNNL1Loss=0.323733,	
INFO:root:Epoch[1] Batch [6420]	Speed: 1.83 samples/sec	Train-RPNAcc=0.903596,	RPNLogLoss=0.222757,	RPNL1Loss=0.140642,	RCNNAcc=0.921592,	RCNNLogLoss=0.221607,	RCNNL1Loss=0.323552,	
INFO:root:Epoch[1] Batch [6440]	Speed: 1.73 samples/sec	Train-RPNAcc=0.903714,	RPNLogLoss=0.222521,	RPNL1Loss=0.140582,	RCNNAcc=0.921619,	RCNNLogLoss=0.221439,	RCNNL1Loss=0.323499,	
INFO:root:Epoch[1] Batch [6460]	Speed: 1.46 samples/sec	Train-RPNAcc=0.903833,	RPNLogLoss=0.222309,	RPNL1Loss=0.140428,	RCNNAcc=0.921677,	RCNNLogLoss=0.221209,	RCNNL1Loss=0.323400,	
INFO:root:Epoch[1] Batch [6480]	Speed: 1.87 samples/sec	Train-RPNAcc=0.903990,	RPNLogLoss=0.222026,	RPNL1Loss=0.140241,	RCNNAcc=0.921729,	RCNNLogLoss=0.221038,	RCNNL1Loss=0.323377,	
INFO:root:Epoch[1] Batch [6500]	Speed: 1.89 samples/sec	Train-RPNAcc=0.904127,	RPNLogLoss=0.221745,	RPNL1Loss=0.140067,	RCNNAcc=0.921813,	RCNNLogLoss=0.220837,	RCNNL1Loss=0.323326,	
INFO:root:Epoch[1] Batch [6520]	Speed: 1.79 samples/sec	Train-RPNAcc=0.904243,	RPNLogLoss=0.221525,	RPNL1Loss=0.139983,	RCNNAcc=0.921837,	RCNNLogLoss=0.220683,	RCNNL1Loss=0.323334,	
INFO:root:Epoch[1] Batch [6540]	Speed: 1.80 samples/sec	Train-RPNAcc=0.904361,	RPNLogLoss=0.221325,	RPNL1Loss=0.139970,	RCNNAcc=0.921898,	RCNNLogLoss=0.220495,	RCNNL1Loss=0.323331,	
INFO:root:Epoch[1] Batch [6560]	Speed: 1.83 samples/sec	Train-RPNAcc=0.904524,	RPNLogLoss=0.221018,	RPNL1Loss=0.139752,	RCNNAcc=0.921976,	RCNNLogLoss=0.220246,	RCNNL1Loss=0.323199,	
INFO:root:Epoch[1] Batch [6580]	Speed: 1.75 samples/sec	Train-RPNAcc=0.904647,	RPNLogLoss=0.220794,	RPNL1Loss=0.139623,	RCNNAcc=0.921994,	RCNNLogLoss=0.220110,	RCNNL1Loss=0.323185,	
INFO:root:Epoch[1] Batch [6600]	Speed: 1.88 samples/sec	Train-RPNAcc=0.904794,	RPNLogLoss=0.220517,	RPNL1Loss=0.139427,	RCNNAcc=0.922029,	RCNNLogLoss=0.219969,	RCNNL1Loss=0.323124,	
INFO:root:Epoch[1] Batch [6620]	Speed: 1.87 samples/sec	Train-RPNAcc=0.904904,	RPNLogLoss=0.220290,	RPNL1Loss=0.139335,	RCNNAcc=0.922090,	RCNNLogLoss=0.219725,	RCNNL1Loss=0.323072,	
INFO:root:Epoch[1] Batch [6640]	Speed: 1.84 samples/sec	Train-RPNAcc=0.905028,	RPNLogLoss=0.220045,	RPNL1Loss=0.139195,	RCNNAcc=0.922147,	RCNNLogLoss=0.219570,	RCNNL1Loss=0.323117,	
INFO:root:Epoch[1] Batch [6660]	Speed: 1.91 samples/sec	Train-RPNAcc=0.905155,	RPNLogLoss=0.219760,	RPNL1Loss=0.139091,	RCNNAcc=0.922216,	RCNNLogLoss=0.219341,	RCNNL1Loss=0.323054,	
INFO:root:Epoch[1] Batch [6680]	Speed: 1.83 samples/sec	Train-RPNAcc=0.905255,	RPNLogLoss=0.219527,	RPNL1Loss=0.138927,	RCNNAcc=0.922233,	RCNNLogLoss=0.219182,	RCNNL1Loss=0.322975,	
INFO:root:Epoch[1] Batch [6700]	Speed: 1.97 samples/sec	Train-RPNAcc=0.905451,	RPNLogLoss=0.219160,	RPNL1Loss=0.138735,	RCNNAcc=0.922344,	RCNNLogLoss=0.218852,	RCNNL1Loss=0.322780,	
INFO:root:Epoch[1] Batch [6720]	Speed: 1.91 samples/sec	Train-RPNAcc=0.905617,	RPNLogLoss=0.218819,	RPNL1Loss=0.138472,	RCNNAcc=0.922454,	RCNNLogLoss=0.218538,	RCNNL1Loss=0.322584,	
INFO:root:Epoch[1] Batch [6740]	Speed: 1.70 samples/sec	Train-RPNAcc=0.905736,	RPNLogLoss=0.218584,	RPNL1Loss=0.138368,	RCNNAcc=0.922486,	RCNNLogLoss=0.218389,	RCNNL1Loss=0.322524,	
INFO:root:Epoch[1] Batch [6760]	Speed: 1.80 samples/sec	Train-RPNAcc=0.905897,	RPNLogLoss=0.218303,	RPNL1Loss=0.138298,	RCNNAcc=0.922552,	RCNNLogLoss=0.218215,	RCNNL1Loss=0.322341,	
INFO:root:Epoch[1] Batch [6780]	Speed: 1.71 samples/sec	Train-RPNAcc=0.905987,	RPNLogLoss=0.218146,	RPNL1Loss=0.138196,	RCNNAcc=0.922544,	RCNNLogLoss=0.218138,	RCNNL1Loss=0.322376,	
INFO:root:Epoch[1] Batch [6800]	Speed: 1.88 samples/sec	Train-RPNAcc=0.906116,	RPNLogLoss=0.217898,	RPNL1Loss=0.138088,	RCNNAcc=0.922623,	RCNNLogLoss=0.217881,	RCNNL1Loss=0.322243,	
INFO:root:Epoch[1] Batch [6820]	Speed: 1.89 samples/sec	Train-RPNAcc=0.906269,	RPNLogLoss=0.217599,	RPNL1Loss=0.137938,	RCNNAcc=0.922724,	RCNNLogLoss=0.217627,	RCNNL1Loss=0.322071,	
INFO:root:Epoch[1] Batch [6840]	Speed: 1.90 samples/sec	Train-RPNAcc=0.906408,	RPNLogLoss=0.217323,	RPNL1Loss=0.137758,	RCNNAcc=0.922829,	RCNNLogLoss=0.217351,	RCNNL1Loss=0.321997,	
INFO:root:Epoch[1] Train-RPNAcc=0.906441
INFO:root:Epoch[1] Train-RPNLogLoss=0.217285
INFO:root:Epoch[1] Train-RPNL1Loss=0.137716
INFO:root:Epoch[1] Train-RCNNAcc=0.922857
INFO:root:Epoch[1] Train-RCNNLogLoss=0.217293
INFO:root:Epoch[1] Train-RCNNL1Loss=0.321952
INFO:root:Epoch[1] Time cost=4488.201
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
600
[07:27:34] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [07:27:34] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0577f2771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f0578042ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f05787163da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0621456adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f062145640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f062166d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f062166ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f06229e4f45]
[bt] (32) python() [0x578c4e]

Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 143, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 436, in fit
    callback(epoch, self.symbol, arg_params, aux_params)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/callback.py", line 41, in _callback
    arg['bbox_pred_weight_test'] = (arg['bbox_pred_weight'].T * mx.nd.array(stds)).T
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 141, in __mul__
    return multiply(self, other)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 763, in multiply
    None)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 683, in _ufunc_helper
    return fn_array(lhs, rhs)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/ndarray.py", line 131, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [07:27:34] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0577f2771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f0578042ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f05787163da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0621456adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f062145640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f062166d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f062166ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f06229e4f45]
[bt] (32) python() [0x578c4e]

{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_reshape_output': (1L, 128L, 21L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 256L, 42L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (84L,),
 'dim_pred_weight': (84L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[07:31:50] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
600
Traceback (most recent call last):
  File "train_end2end.py", line 190, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 143, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/mx-rcnn/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
  File "train_end2end.py", line 127
    conf_metric = mx.metric.RCNNConfLossMetric()
    ^
IndentationError: unexpected indent
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_reshape_output': (1L, 128L, 21L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (84L,),
 'dim_pred_weight': (84L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 195, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 127, in train_net
    conf_metric = mx.metric.RCNNConfLossMetric()
AttributeError: 'module' object has no attribute 'RCNNConfLossMetric'
  File "train_end2end.py", line 128
    RCNNConfLossMetric
    ^
IndentationError: unexpected indent
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_reshape_output': (1L, 128L, 21L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (84L,),
 'dim_pred_weight': (84L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 9L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[07:49:48] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 1.97 samples/sec	Train-RPNAcc=0.552083,	RPNLogLoss=0.695397,	RPNL1Loss=0.399612,	RCNNAcc=0.146577,	RCNNLogLoss=2.959453,	RCNNL1Loss=0.415573,	
INFO:root:Epoch[1] Batch [40]	Speed: 1.92 samples/sec	Train-RPNAcc=0.594322,	RPNLogLoss=0.693180,	RPNL1Loss=0.426425,	RCNNAcc=0.391387,	RCNNLogLoss=2.752283,	RCNNL1Loss=0.381126,	
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cla_prob_reshape_output': (1L, 128L, 21L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 84L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cla_score_bias': (21L,),
 'cla_score_weight': (21L, 4096L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dim_pred_bias': (84L,),
 'dim_pred_weight': (84L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[07:50:46] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
INFO:root:Epoch[1] Batch [20]	Speed: 2.28 samples/sec	Train-RPNAcc=0.554129,	RPNLogLoss=0.695174,	RPNL1Loss=0.507560,	RCNNAcc=0.146577,	RCNNLogLoss=2.969119,	RCNNL1Loss=0.415698,	RCNNConfLoss=3.082990,	RCNNDimLoss=11.769796,	
INFO:root:Epoch[1] Batch [40]	Speed: 2.23 samples/sec	Train-RPNAcc=0.601467,	RPNLogLoss=0.693006,	RPNL1Loss=0.460540,	RCNNAcc=0.376334,	RCNNLogLoss=2.767760,	RCNNL1Loss=0.465753,	RCNNConfLoss=2.819485,	RCNNDimLoss=7.721403,	
INFO:root:Epoch[1] Batch [60]	Speed: 2.33 samples/sec	Train-RPNAcc=0.611680,	RPNLogLoss=0.691899,	RPNL1Loss=0.468288,	RCNNAcc=0.524206,	RCNNLogLoss=2.630714,	RCNNL1Loss=0.450286,	RCNNConfLoss=2.664231,	RCNNDimLoss=5.809669,	
INFO:root:Epoch[1] Batch [80]	Speed: 2.32 samples/sec	Train-RPNAcc=0.621431,	RPNLogLoss=0.691111,	RPNL1Loss=0.481868,	RCNNAcc=0.613040,	RCNNLogLoss=2.521150,	RCNNL1Loss=0.402595,	RCNNConfLoss=2.546068,	RCNNDimLoss=4.691010,	
Traceback (most recent call last):
  File "train_end2end.py", line 9, in <module>
    from rcnn.symbol import *
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/__init__.py", line 1, in <module>
    from symbol_vgg import *
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 501
    dim_loss = mx.symbol.Reshape(data=dim_loss, shape=(config.TRAIN.BATCH_IMAGES, -1, 3), name='dim_loss_reshape')
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "train_end2end.py", line 9, in <module>
    from rcnn.symbol import *
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/__init__.py", line 1, in <module>
    from symbol_vgg import *
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 502
    angle_loss = mx.symbol.Reshape(data=angle_loss, shape=(config.TRAIN.BATCH_IMAGES, -1, num_bin*2), name='angle_loss_reshape')
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "train_end2end.py", line 192, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 480, in get_vgg_train
    L2_norm = mxnet.symbol.L2Normalization(data=fc8_angle_reshape, mode='spatial', name='L2_norm')
NameError: global name 'mxnet' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L),
 'softmax_label': (128L,)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 192, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 95, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc6_dim_weight not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L),
 'softmax_label': (128L,)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 201, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 104, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc6_dim_weight not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L),
 'softmax_label': (128L,)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L),
 'softmax_label': (128L,)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 18L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'label_reshape_output': (1L, 128L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'blockgrad4_output': (128L, 5L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_bbox_target': (128L, 84L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_bbox_target': (128L, 84L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/mx-rcnn/rcnn/symbol/symbol_vgg.py", line 507, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label), relu5_3, rois, poll5, bbox_target])
NameError: global name 'poll5' is not defined
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_bbox_target': (128L, 84L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 10L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 10L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'gt_boxes': (1L, 5L, 5L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'gt_boxes': (1L, 1L, 5L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'gt_boxes': (1L, 5L, 5L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'gt_boxes': (1L, 4L, 5L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'gt_boxes': (1L, 9L, 5L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 303L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 9L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 4L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'bbox_pred_output': (128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L,),
 'blockgrad3_output': (128L,),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'cls_score_output': (128L, 21L),
 'custom0_label': (128L,),
 'custom0_rois_output': (128L, 5L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'drop6_output': (128L, 4096L),
 'drop7_output': (128L, 4096L),
 'fc6_output': (128L, 4096L),
 'flatten_output': (128L, 25088L),
 'gt_boxes': (1L, 3L, 5L),
 'relu5_3_output': (1L, 512L, 18L, 62L),
 'roi_pool5_output': (128L, 512L, 7L, 7L),
 'rois_output': (6000L, 5L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'angle_label': (128L,),
 'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conf_label': (128L,),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'dims_label': (128L, 3L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (256L,),
 'fc7_conf_weight': (256L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (4L,),
 'fc8_conf_weight': (4L, 256L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "train_end2end.py", line 215, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "train_end2end.py", line 118, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: dims_label not initialized
